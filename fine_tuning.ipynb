{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Fine-Tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univeral Code Used for the Entire Notebook\n",
    "\n",
    "Let's set up our libraries and client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import json  # Handles JSON data encoding and decoding\n",
    "import random  # Generates random numbers and makes random selections\n",
    "import time  # Provides time-related functions\n",
    "import math  # Offers mathematical functions and constants\n",
    "from pathlib import Path  # Handles filesystem paths in an object-oriented way\n",
    "from collections import defaultdict  # Provides a dictionary subclass with default values\n",
    "import base64  # Provides data encoding and decoding as specified in RFC 3548\n",
    "import io  # Offers core tools for working with streams\n",
    "import sys  # Provides access to some variables used or maintained by the interpreter\n",
    "\n",
    "# Third-party library imports\n",
    "import numpy as np  # Supports large, multi-dimensional arrays and matrices\n",
    "import pandas as pd  # Offers data manipulation and analysis tools\n",
    "import tiktoken  # Handles tokenization for OpenAI models\n",
    "from openai import OpenAI, RateLimitError  # OpenAI API client and related error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the OpenAI client\n",
    "client = OpenAI()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Files Validation & Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load and print the dataset\n",
    "def load_and_print_dataset(data_path):\n",
    "    \"\"\"\n",
    "    Load the dataset from a given file path and print initial statistics.\n",
    "    \n",
    "    Args:\n",
    "        data_path (str): Path to the dataset file.\n",
    "        \n",
    "    Returns:\n",
    "        dataset (list): Loaded dataset as a list of dictionaries.\n",
    "    \"\"\"\n",
    "    # Load the dataset\n",
    "    with open(data_path, 'r', encoding='utf-8') as file:\n",
    "        dataset = [json.loads(line) for line in file]\n",
    "    \n",
    "    # Print initial dataset statistics\n",
    "    print(\"Number of examples:\", len(dataset))\n",
    "    print(\"First example:\")\n",
    "    \n",
    "    # Print messages from the first example in the dataset\n",
    "    for message in dataset[0][\"messages\"]:\n",
    "        print(message)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 100\n",
      "First example:\n",
      "{'role': 'system', 'content': 'Marv is a factual chatbot that is also sarcastic.'}\n",
      "{'role': 'user', 'content': \"What's the tallest mountain in the world?\"}\n",
      "{'role': 'assistant', 'content': \"Mount Everest. It's only the tallest thing on the planet.\"}\n"
     ]
    }
   ],
   "source": [
    "# Using the function to load and print the dataset\n",
    "data_path = \"./artifacts/marv_fine_tune.jsonl\"\n",
    "dataset = load_and_print_dataset(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format Validation\n",
    "\n",
    "We can perform a variety of error checks to validate that each conversation in the dataset adheres to the format expected by the fine-tuning API. Errors are categorized based on their nature for easier debugging.\n",
    "\n",
    "1. **Data Type Check**: Checks whether each entry in the dataset is a dictionary (dict). Error type: `data_type`.\n",
    "\n",
    "2. **Presence of Message List**: Checks if a `messages` list is present in each entry. Error type: `missing_messages_list`.\n",
    "\n",
    "3. **Message Keys Check**: Validates that each message in the `messages` list contains the keys `role` and `content`. Error type: `message_missing_key`.\n",
    "\n",
    "4. **Unrecognized Keys in Messages**: Logs if a message has keys other than `role`, `content`, `weight`, `function_call`, and `name`. Error type: `message_unrecognized_key`.\n",
    "\n",
    "5. **Role Validation**: Ensures the `role` is one of \"system\", \"user\", or \"assistant\". Error type: `unrecognized_role`.\n",
    "\n",
    "6. **Content Validation**: Verifies that `content` has textual data and is a string. Error type: `missing_content`.\n",
    "\n",
    "7. **Assistant Message Presence**: Checks that each conversation has at least one message from the assistant. Error type: `example_missing_assistant_message`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check for format errors in our file\n",
    "def check_format_errors(dataset):\n",
    "    \"\"\"\n",
    "    Check for format errors in the dataset and print the results.\n",
    "    \n",
    "    Args:\n",
    "        dataset (list): The dataset to check.\n",
    "        \n",
    "    Returns:\n",
    "        format_errors (dict): A dictionary containing the count of each type of format error.\n",
    "    \"\"\"\n",
    "    # Dictionary to track format errors\n",
    "    format_errors = defaultdict(int)\n",
    "    \n",
    "    # Iterate through each example in the dataset\n",
    "    for ex in dataset:\n",
    "        # Check if the example is a dictionary\n",
    "        if not isinstance(ex, dict):\n",
    "            format_errors[\"data_type\"] += 1\n",
    "            continue\n",
    "        \n",
    "        # Retrieve the messages list from the example\n",
    "        messages = ex.get(\"messages\", None)\n",
    "        if not messages:\n",
    "            format_errors[\"missing_messages_list\"] += 1\n",
    "            continue\n",
    "        \n",
    "        # Check each message in the messages list\n",
    "        for message in messages:\n",
    "            # Check if required keys are present in the message\n",
    "            if \"role\" not in message or \"content\" not in message:\n",
    "                format_errors[\"message_missing_key\"] += 1\n",
    "            \n",
    "            # Check for any unrecognized keys in the message\n",
    "            if any(k not in (\"role\", \"content\", \"name\", \"function_call\", \"weight\") for k in message):\n",
    "                format_errors[\"message_unrecognized_key\"] += 1\n",
    "            \n",
    "            # Validate the role value in the message\n",
    "            if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\", \"function\"):\n",
    "                format_errors[\"unrecognized_role\"] += 1\n",
    "            \n",
    "            # Check content and function_call in the message\n",
    "            content = message.get(\"content\", None)\n",
    "            function_call = message.get(\"function_call\", None)\n",
    "            if (not content and not function_call) or not isinstance(content, str):\n",
    "                format_errors[\"missing_content\"] += 1\n",
    "        \n",
    "        # Ensure at least one message from the assistant is present\n",
    "        if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
    "            format_errors[\"example_missing_assistant_message\"] += 1\n",
    "    \n",
    "    # Print the results of the error checks\n",
    "    if format_errors:\n",
    "        print(\"Found possible issues:\")\n",
    "        for key, value in format_errors.items():\n",
    "            print(f\"{key}: {value}\")\n",
    "    else:\n",
    "        print(\"No errors found\")\n",
    "    \n",
    "    return format_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors found\n"
     ]
    }
   ],
   "source": [
    "# Using the function to check for format errors\n",
    "format_errors = check_format_errors(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token Counting Utilities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Warnings, Token Counts, and Cost Estimation\n",
    "\n",
    "With some lightweight analysis we can identify potential issues in the dataset, like missing messages, and provide statistical insights into message and token counts.\n",
    "\n",
    "1. **Missing System/User Messages**: Counts the number of conversations missing a \"system\" or \"user\" message. Such messages are critical for defining the assistant's behavior and initiating the conversation.\n",
    "\n",
    "2. **Number of Messages Per Example**: Summarizes the distribution of the number of messages in each conversation, providing insight into dialogue complexity.\n",
    "\n",
    "3. **Total Tokens Per Example**: Calculates and summarizes the distribution of the total number of tokens in each conversation. Important for understanding fine-tuning costs.\n",
    "\n",
    "4. **Tokens in Assistant's Messages**: Calculates the number of tokens in the assistant's messages per conversation and summarizes this distribution. Useful for understanding the assistant's verbosity.\n",
    "\n",
    "5. **Token Limit Warnings**: Checks if any examples exceed the maximum token limit (16,385 tokens), as such examples will be truncated during fine-tuning, potentially resulting in data loss.\n",
    "\n",
    "\n",
    "Finally, we estimate the total number of tokens that will be used for fine-tuning, which allows us to approximate the cost. It is worth noting that the duration of the fine-tuning jobs will also increase with the token count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "MAX_TOKENS_PER_EXAMPLE = 640\n",
    "TARGET_EPOCHS = 3\n",
    "MIN_TARGET_EXAMPLES = 10\n",
    "MAX_TARGET_EXAMPLES = 25000\n",
    "MIN_DEFAULT_EPOCHS = 1\n",
    "MAX_DEFAULT_EPOCHS = 25\n",
    "\n",
    "# Automatically get the encoding for a specific model\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "\n",
    "\n",
    "def process_dataset(dataset, num_tokens_from_messages,\n",
    "                    num_assistant_tokens_from_messages, token_limit=64000):\n",
    "    \"\"\"\n",
    "    Process the dataset and calculate various statistics.\n",
    "\n",
    "    Args:\n",
    "        dataset (list): List of examples in the dataset.\n",
    "        num_tokens_from_messages (function): Function to count tokens in messages.\n",
    "        num_assistant_tokens_from_messages (function): Function to count assistant tokens.\n",
    "        token_limit (int): Maximum token limit for conversations.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Contains lists of message counts, conversation lengths, and assistant message lengths.\n",
    "    \"\"\"\n",
    "    n_missing_system = 0\n",
    "    n_missing_user = 0\n",
    "    n_messages = []\n",
    "    convo_lens = []\n",
    "    assistant_message_lens = []\n",
    "\n",
    "    for i, ex in enumerate(dataset):\n",
    "        messages = ex[\"messages\"]\n",
    "        if not any(message[\"role\"] == \"system\" for message in messages):\n",
    "            n_missing_system += 1\n",
    "        if not any(message[\"role\"] == \"user\" for message in messages):\n",
    "            n_missing_user += 1\n",
    "        n_messages.append(len(messages))\n",
    "        try:\n",
    "            convo_lens.append(num_tokens_from_messages(messages))\n",
    "            assistant_message_lens.append(\n",
    "                num_assistant_tokens_from_messages(messages)\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing example {i}:\")\n",
    "            print(f\"Messages: {messages}\")\n",
    "            print(f\"Error: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    n_too_long = sum(l > token_limit for l in convo_lens)\n",
    "\n",
    "    print_summary(n_missing_system, n_missing_user, n_messages,\n",
    "                convo_lens, assistant_message_lens, n_too_long, token_limit)\n",
    "    return n_messages, convo_lens, assistant_message_lens\n",
    "\n",
    "\n",
    "def print_summary(n_missing_system, n_missing_user, n_messages,\n",
    "                convo_lens, assistant_message_lens, n_too_long, token_limit):\n",
    "    \"\"\"\n",
    "    Print a summary of the dataset processing results.\n",
    "\n",
    "    Args:\n",
    "        n_missing_system (int): Number of examples missing system messages.\n",
    "        n_missing_user (int): Number of examples missing user messages.\n",
    "        n_messages (list): List of message counts for each example.\n",
    "        convo_lens (list): List of conversation lengths in tokens.\n",
    "        assistant_message_lens (list): List of assistant message lengths in tokens.\n",
    "        n_too_long (int): Number of conversations exceeding the token limit.\n",
    "        token_limit (int): Maximum token limit for conversations.\n",
    "    \"\"\"\n",
    "    print(\"Summary of dataset processing:\")\n",
    "    print(f\"Num examples missing system message: {n_missing_system}\")\n",
    "    print(f\"Num examples missing user message: {n_missing_user}\")\n",
    "    print(f\"Total number of examples: {len(n_messages)}\")\n",
    "    print(f\"Average number of messages per example: \"\n",
    "        f\"{sum(n_messages) / len(n_messages):.2f}\")\n",
    "    print(f\"Average number of total tokens per example: \"\n",
    "        f\"{sum(convo_lens) / len(convo_lens):.2f}\")\n",
    "    print(f\"Average number of assistant tokens per example: \"\n",
    "        f\"{sum(assistant_message_lens) / len(assistant_message_lens):.2f}\")\n",
    "    print(f\"{n_too_long} examples may be over the {token_limit} token limit \"\n",
    "        f\"and will be truncated during fine-tuning\")\n",
    "\n",
    "\n",
    "def calculate_epochs(n_train_examples):\n",
    "    \"\"\"\n",
    "    Calculate the number of epochs based on the number of training examples.\n",
    "\n",
    "    Args:\n",
    "        n_train_examples (int): Number of training examples.\n",
    "\n",
    "    Returns:\n",
    "        int: Calculated number of epochs.\n",
    "    \"\"\"\n",
    "    if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:\n",
    "        return min(MAX_DEFAULT_EPOCHS,\n",
    "                math.ceil(MIN_TARGET_EXAMPLES / n_train_examples))\n",
    "    elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES:\n",
    "        return max(MIN_DEFAULT_EPOCHS,\n",
    "                   MAX_TARGET_EXAMPLES // n_train_examples)\n",
    "    return TARGET_EPOCHS\n",
    "\n",
    "\n",
    "def calculate_billing_tokens(convo_lens):\n",
    "    \"\"\"\n",
    "    Calculate the number of billing tokens in the dataset.\n",
    "\n",
    "    Args:\n",
    "        convo_lens (list): List of conversation lengths in tokens.\n",
    "\n",
    "    Returns:\n",
    "        int: Total number of billing tokens.\n",
    "    \"\"\"\n",
    "    return sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in convo_lens)\n",
    "\n",
    "\n",
    "def print_dataset_statistics(n_train_examples, convo_lens):\n",
    "    \"\"\"\n",
    "    Print the dataset statistics and billing information.\n",
    "\n",
    "    Args:\n",
    "        n_train_examples (int): Number of training examples.\n",
    "        convo_lens (list): List of conversation lengths in tokens.\n",
    "    \"\"\"\n",
    "    n_epochs = calculate_epochs(n_train_examples)\n",
    "    n_billing_tokens = calculate_billing_tokens(convo_lens)\n",
    "\n",
    "    print(f\"Dataset Statistics:\")\n",
    "    print(f\"- Number of training examples: {n_train_examples}\")\n",
    "    print(f\"- Approximate billable tokens: {n_billing_tokens}\")\n",
    "    print(f\"- Default number of epochs: {n_epochs}\")\n",
    "    print(f\"- Estimated total billable tokens: {n_epochs * n_billing_tokens}\")\n",
    "\n",
    "\n",
    "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
    "    \"\"\"\n",
    "    Calculate the number of tokens in a list of messages.\n",
    "\n",
    "    Args:\n",
    "        messages (list): List of message dictionaries.\n",
    "        tokens_per_message (int): Base tokens per message.\n",
    "        tokens_per_name (int): Additional tokens for the 'name' field.\n",
    "\n",
    "    Returns:\n",
    "        int: Total number of tokens.\n",
    "    \"\"\"\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            if key == \"content\" and value is None:\n",
    "                continue\n",
    "            elif key == \"function_call\":\n",
    "                num_tokens += len(encoding.encode(json.dumps(value)))\n",
    "            else:\n",
    "                try:\n",
    "                    num_tokens += len(encoding.encode(str(value)))\n",
    "                except Exception as e:\n",
    "                    print(f\"Error encoding key: {key}, value: {value}, \"\n",
    "                        f\"type: {type(value)}\")\n",
    "                    print(f\"Error message: {str(e)}\")\n",
    "                    raise\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3  # Adding 3 tokens for end of sequence\n",
    "    return num_tokens\n",
    "\n",
    "\n",
    "def num_assistant_tokens_from_messages(messages):\n",
    "    \"\"\"\n",
    "    Calculate the number of tokens in assistant messages.\n",
    "\n",
    "    Args:\n",
    "        messages (list): List of message dictionaries.\n",
    "\n",
    "    Returns:\n",
    "        int: Total number of tokens in assistant messages.\n",
    "    \"\"\"\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"assistant\":\n",
    "            if message.get(\"content\") is not None:\n",
    "                num_tokens += len(encoding.encode(str(message[\"content\"])))\n",
    "            if \"function_call\" in message:\n",
    "                num_tokens += len(encoding.encode(json.dumps(message[\"function_call\"])))\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of dataset processing:\n",
      "Num examples missing system message: 0\n",
      "Num examples missing user message: 0\n",
      "Total number of examples: 100\n",
      "Average number of messages per example: 3.00\n",
      "Average number of total tokens per example: 46.01\n",
      "Average number of assistant tokens per example: 10.54\n",
      "0 examples may be over the 64000 token limit and will be truncated during fine-tuning\n",
      "Dataset Statistics:\n",
      "- Number of training examples: 100\n",
      "- Approximate billable tokens: 4601\n",
      "- Default number of epochs: 3\n",
      "- Estimated total billable tokens: 13803\n"
     ]
    }
   ],
   "source": [
    "# Process the dataset and extract relevant information\n",
    "n_messages, convo_lens, assistant_message_lens = process_dataset(\n",
    "    dataset,\n",
    "    num_tokens_from_messages,\n",
    "    num_assistant_tokens_from_messages\n",
    ")\n",
    "\n",
    "# Get the total number of examples in the dataset\n",
    "n_train_examples = len(dataset)\n",
    "\n",
    "# Print statistics about the dataset\n",
    "print_dataset_statistics(n_train_examples, convo_lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train / Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train / Test Split Function for JSONL Files\n",
    "def split_jsonl_file(file_path, train_ratio=0.8):\n",
    "    # Read the input file\n",
    "    file_path = Path(file_path)\n",
    "    with file_path.open('r', encoding='utf-8') as f:\n",
    "        data = [json.loads(line) for line in f]\n",
    "    \n",
    "    # Shuffle the data\n",
    "    random.shuffle(data)\n",
    "    \n",
    "    # Calculate split index\n",
    "    split_index = int(len(data) * train_ratio)\n",
    "    \n",
    "    # Split the data\n",
    "    train_data = data[:split_index]\n",
    "    test_data = data[split_index:]\n",
    "    \n",
    "    # Prepare output file paths\n",
    "    train_file = file_path.with_name(f\"{file_path.stem}_train{file_path.suffix}\")\n",
    "    test_file = file_path.with_name(f\"{file_path.stem}_test{file_path.suffix}\")\n",
    "    \n",
    "    # Write train data\n",
    "    with train_file.open('w', encoding='utf-8') as f:\n",
    "        for item in train_data:\n",
    "            json.dump(item, f)\n",
    "            f.write('\\n')\n",
    "    \n",
    "    # Write test data\n",
    "    with test_file.open('w', encoding='utf-8') as f:\n",
    "        for item in test_data:\n",
    "            json.dump(item, f)\n",
    "            f.write('\\n')\n",
    "    \n",
    "    print(f\"Train data saved to: {train_file}\")\n",
    "    print(f\"Test data saved to: {test_file}\")\n",
    "    print(f\"Train set size: {len(train_data)}\")\n",
    "    print(f\"Test set size: {len(test_data)}\")\n",
    "    \n",
    "    return(train_file, test_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data saved to: artifacts\\marv_fine_tune_train.jsonl\n",
      "Test data saved to: artifacts\\marv_fine_tune_test.jsonl\n",
      "Train set size: 80\n",
      "Test set size: 20\n",
      "\n",
      "\n",
      "Train file path: artifacts\\marv_fine_tune_train.jsonl\n",
      "Test file path: artifacts\\marv_fine_tune_test.jsonl\n"
     ]
    }
   ],
   "source": [
    "# File paths and data processing\n",
    "file_path = \"./artifacts/marv_fine_tune.jsonl\"\n",
    "\n",
    "# Split the JSONL file into train and test sets\n",
    "train_test_files = split_jsonl_file(file_path)\n",
    "print(\"\\n\")  # Print a blank line for better output readability\n",
    "\n",
    "# Convert the returned file paths to strings\n",
    "train_path, test_path = [str(file) for file in train_test_files]\n",
    "\n",
    "# Print the paths of the resulting train and test files\n",
    "print(f\"Train file path: {train_path}\")\n",
    "print(f\"Test file path: {test_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Fine-Tuning Job\n",
    "\n",
    "### Uploading Training and Test Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the training data to the OpenAI API\n",
    "train__set_file = client.files.create(\n",
    "            file=open(train_path, \"rb\"),\n",
    "            purpose=\"fine-tune\"\n",
    "            )\n",
    "\n",
    "# Upload the test data to the OpenAI API\n",
    "test_set_file = client.files.create(\n",
    "            file=open(test_path, \"rb\"),\n",
    "            purpose=\"fine-tune\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Simple Fine-Tuning Job (Code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a fine-tuning job using the uploaded training data\n",
    "simple_ft_job = client.fine_tuning.jobs.create(\n",
    "    training_file=train__set_file.id, \n",
    "    model=\"gpt-4o-mini-2024-07-18\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Fine-Tuning Job with All Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a fine-tuning job using the uploaded training data\n",
    "all_params_ft_job = client.fine_tuning.jobs.create(\n",
    "    model=\"gpt-4o-mini-2024-07-18\",  # Base model to be fine-tuned\n",
    "    training_file=train__set_file.id,  # ID of the uploaded training data file\n",
    "    validation_file=test_set_file.id,  # ID of the uploaded validation (test) data file\n",
    "    hyperparameters={\n",
    "        \"batch_size\": \"auto\",  # Let API automatically determine batch size\n",
    "        \"learning_rate_multiplier\": \"auto\",  # Auto-set learning rate multiplier\n",
    "        \"n_epochs\": \"auto\",  # Automatically decide number of training epochs\n",
    "    },\n",
    "    suffix=\"marv_ft_0003\",  # Append this to the fine-tuned model's name\n",
    "    integrations=None,  # Specific integrations used\n",
    "    seed=None,  # Specific random seed set for reproducibility\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the Training Metrics\n",
    "\n",
    "### Pulling Training Metrics Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This set of code will check the status of the fine-tuning job\n",
    "# Repeating the check every 60 seconds until the job is done\n",
    "\n",
    "class FineTuningFailedException(Exception):\n",
    "    \"\"\"Custom exception for failed fine-tuning jobs.\"\"\"\n",
    "    pass\n",
    "\n",
    "def check_fine_tuning_status(client, job_id):\n",
    "    \"\"\"\n",
    "    Continuously check the status of a fine-tuning job until it succeeds or fails.\n",
    "\n",
    "    Args:\n",
    "        client: The API client object.\n",
    "        job_id: The ID of the fine-tuning job to check.\n",
    "\n",
    "    Returns:\n",
    "        The final job details if the job succeeds.\n",
    "\n",
    "    Raises:\n",
    "        FineTuningFailedException: If the fine-tuning job fails.\n",
    "        Exception: For any other errors during the process.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        try:\n",
    "            # Retrieve updated information for the fine-tuning job\n",
    "            retrieved_job = client.fine_tuning.jobs.retrieve(job_id)\n",
    "            \n",
    "            print(f\"Current status: {retrieved_job.status}\")\n",
    "            \n",
    "            if retrieved_job.status == \"failed\":\n",
    "                print(\"Job failed. Final job details:\")\n",
    "                print(retrieved_job)\n",
    "                raise FineTuningFailedException(\"The fine-tuning job has failed.\")\n",
    "            \n",
    "            if retrieved_job.status == \"succeeded\":\n",
    "                print(\"Job succeeded. Final job details:\")\n",
    "                print(retrieved_job)\n",
    "                return retrieved_job\n",
    "            \n",
    "            # Wait for 60 seconds before checking again\n",
    "            time.sleep(60)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            raise  # Re-raise the exception to stop the function\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current status: running\n",
      "Current status: running\n",
      "Current status: running\n",
      "Current status: running\n",
      "Current status: running\n",
      "Current status: running\n",
      "Current status: running\n",
      "Current status: running\n",
      "Current status: running\n",
      "Current status: running\n",
      "Current status: succeeded\n",
      "Job succeeded. Final job details:\n",
      "FineTuningJob(id='ftjob-iNtCqKhdZUJ583nxlavNW3OW', created_at=1723388837, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal:marv-ft-0003:9v4b4nlv', finished_at=1723389392, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-SQH2HT1IvRszon9pdYwV1yvQ', result_files=['file-Kka4BsNhocKqPriFlPs7aSGN'], seed=622433556, status='succeeded', trained_tokens=10521, training_file='file-aRcuFvUVcDiFlTLuJ2zuOf42', validation_file='file-l4XN9lwDjLRdfH1yhQammB2N', estimated_finish=None, integrations=[], user_provided_suffix='marv_ft_0003')\n"
     ]
    }
   ],
   "source": [
    "# Use the check_fine_tuning_status function\n",
    "\n",
    "# Extract the job ID from the created fine-tuning job\n",
    "job_id = all_params_ft_job.id\n",
    "\n",
    "# Monitor the fine-tuning job status until completion\n",
    "final_job = check_fine_tuning_status(client, job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File saved as step_metrics_ft_gpt-4o-mini-2024-07-18_personal_marv-ft-0003_9v4b4nlv.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_mean_token_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3.07854</td>\n",
       "      <td>0.46154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.32874</td>\n",
       "      <td>0.55000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5.84713</td>\n",
       "      <td>0.57143</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.80234</td>\n",
       "      <td>0.46667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3.73353</td>\n",
       "      <td>0.43750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>236</td>\n",
       "      <td>0.51398</td>\n",
       "      <td>0.84615</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>237</td>\n",
       "      <td>0.14378</td>\n",
       "      <td>0.94444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>238</td>\n",
       "      <td>0.01390</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>239</td>\n",
       "      <td>0.19765</td>\n",
       "      <td>0.92308</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>240</td>\n",
       "      <td>0.00059</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.87948</td>\n",
       "      <td>0.71429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     step  train_loss  train_accuracy  valid_loss  valid_mean_token_accuracy\n",
       "0       1     3.07854         0.46154         NaN                        NaN\n",
       "1       2     2.32874         0.55000         NaN                        NaN\n",
       "2       3     5.84713         0.57143         NaN                        NaN\n",
       "3       4     4.80234         0.46667         NaN                        NaN\n",
       "4       5     3.73353         0.43750         NaN                        NaN\n",
       "..    ...         ...             ...         ...                        ...\n",
       "235   236     0.51398         0.84615         NaN                        NaN\n",
       "236   237     0.14378         0.94444         NaN                        NaN\n",
       "237   238     0.01390         1.00000         NaN                        NaN\n",
       "238   239     0.19765         0.92308         NaN                        NaN\n",
       "239   240     0.00059         1.00000     0.87948                    0.71429\n",
       "\n",
       "[240 rows x 5 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to get the training metrics for a fine-tuning job\n",
    "def fetch_and_process_fine_tuning_metrics(client, fine_tuning_job_id):\n",
    "    # Function to replace colons with underscores for file names\n",
    "    def replace_colons_with_underscores(input_string):\n",
    "        return input_string.replace(':', '_')\n",
    "    \n",
    "    # Get the training metrics for the fine-tuning job\n",
    "    fine_tune_job = client.fine_tuning.jobs.retrieve(fine_tuning_job_id)\n",
    "        \n",
    "    # File ID of the file you want to download\n",
    "    file_id = fine_tune_job.result_files[0]\n",
    "    \n",
    "    # Retrieve the file content directly\n",
    "    response = client.files.content(file_id)\n",
    "    \n",
    "    # Decode the Base64 content\n",
    "    decoded_content = base64.b64decode(response.content).decode('utf-8')\n",
    "    \n",
    "    # Create a DataFrame from the decoded content\n",
    "    df = pd.read_csv(io.StringIO(decoded_content))\n",
    "        \n",
    "    # Save the CSV file locally:\n",
    "    metrics_file_name = \"step_metrics_\" + replace_colons_with_underscores(fine_tune_job.fine_tuned_model + \".csv\")\n",
    "    df.to_csv(metrics_file_name, index=False)\n",
    "    print(f\"\\nFile saved as {metrics_file_name}\")\n",
    "    \n",
    "    # Return our dataframe in case the caller wants to do more with it\n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "fetch_and_process_fine_tuning_metrics(client, all_params_ft_job .id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Fine-Tuning Jobs\n",
    "\n",
    "### List Fine-Tuning Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncCursorPage[FineTuningJob](data=[FineTuningJob(id='ftjob-WcdcO2exERwuEIK1fEcM2JBT', created_at=1723400659, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal:marv-wandb-tune:9v7hfQoT', finished_at=1723401333, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-SQH2HT1IvRszon9pdYwV1yvQ', result_files=['file-9rvOEZkwsslSW94AI2J0GcBU'], seed=32159879, status='succeeded', trained_tokens=10542, training_file='file-oeSDEG9qQLA9aGSL3wN8yLsO', validation_file='file-4sbdIBCMl6yGsqIpVrjmuA0c', estimated_finish=None, integrations=[FineTuningJobWandbIntegrationObject(type='wandb', wandb=FineTuningJobWandbIntegration(project='Marv_Fun_Tune_v2', entity='suspicious-cow-self', name=None, tags=None, run_id='ftjob-WcdcO2exERwuEIK1fEcM2JBT'))], user_provided_suffix='marv_wandb_tune'), FineTuningJob(id='ftjob-ueWCuRQ1x3VqEXRAjJ6Kv5Oa', created_at=1723398372, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal:marv-wandb-tune:9v76i8se', finished_at=1723399043, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-SQH2HT1IvRszon9pdYwV1yvQ', result_files=['file-oXMrlE3x99TFndZQmrZVN9I5'], seed=1247741678, status='succeeded', trained_tokens=10608, training_file='file-37l1glvfRliTHJkHtP88Bbe3', validation_file='file-7P2PUivVWV5rrp1dLxWfZp5i', estimated_finish=None, integrations=[FineTuningJobWandbIntegrationObject(type='wandb', wandb=FineTuningJobWandbIntegration(project='Marv_Fine_Tuning', entity='suspicious-cow-self', name=None, tags=None, run_id='ftjob-ueWCuRQ1x3VqEXRAjJ6Kv5Oa'))], user_provided_suffix='marv_wandb_tune'), FineTuningJob(id='ftjob-ZjHbXqe1ficE0kvMy7RxfJrE', created_at=1723395965, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal:ftx2-marv-v1:9v6Rv9PA', finished_at=1723396514, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=1.8), model='ft:gpt-4o-mini-2024-07-18:personal::9rCp9Ezz', object='fine_tuning.job', organization_id='org-SQH2HT1IvRszon9pdYwV1yvQ', result_files=['file-zCqqffrKLu5LvDkcnIkDuhRj'], seed=2102238806, status='succeeded', trained_tokens=10521, training_file='file-aRcuFvUVcDiFlTLuJ2zuOf42', validation_file='file-l4XN9lwDjLRdfH1yhQammB2N', estimated_finish=None, integrations=[], user_provided_suffix='FTx2-marv-v1'), FineTuningJob(id='ftjob-iNtCqKhdZUJ583nxlavNW3OW', created_at=1723388837, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal:marv-ft-0003:9v4b4nlv', finished_at=1723389392, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-SQH2HT1IvRszon9pdYwV1yvQ', result_files=['file-Kka4BsNhocKqPriFlPs7aSGN'], seed=622433556, status='succeeded', trained_tokens=10521, training_file='file-aRcuFvUVcDiFlTLuJ2zuOf42', validation_file='file-l4XN9lwDjLRdfH1yhQammB2N', estimated_finish=None, integrations=[], user_provided_suffix='marv_ft_0003'), FineTuningJob(id='ftjob-1SJhNwARrgon5LLTLnqG4Dvx', created_at=1723382387, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal:ftx2-marv:9v2wBVw4', finished_at=1723383013, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=1.8), model='ft:gpt-4o-mini-2024-07-18:personal:marv-fine-tune:9rq4BA6s', object='fine_tuning.job', organization_id='org-SQH2HT1IvRszon9pdYwV1yvQ', result_files=['file-iIlpmp5cScxg9ZpsLMdRZSFD'], seed=639482894, status='succeeded', trained_tokens=10521, training_file='file-aRcuFvUVcDiFlTLuJ2zuOf42', validation_file='file-l4XN9lwDjLRdfH1yhQammB2N', estimated_finish=None, integrations=[], user_provided_suffix='ftx2-marv'), FineTuningJob(id='ftjob-V9xgWRDss6V3gp1jpybSXHdn', created_at=1723343453, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal:marv-ft-0002:9usn2itz', finished_at=1723344006, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-SQH2HT1IvRszon9pdYwV1yvQ', result_files=['file-hZrNiLZGpEl7CGY4k2h49wHL'], seed=1243191334, status='succeeded', trained_tokens=10521, training_file='file-aRcuFvUVcDiFlTLuJ2zuOf42', validation_file='file-l4XN9lwDjLRdfH1yhQammB2N', estimated_finish=None, integrations=[], user_provided_suffix='marv_ft_0002'), FineTuningJob(id='ftjob-iSjFrat8Pcfeyug3kwL2FM9M', created_at=1723343327, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal:marv-ft-0001:9uskwWby', finished_at=1723343877, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-SQH2HT1IvRszon9pdYwV1yvQ', result_files=['file-hXrxcAJsUC18wgtz6ElTAWt2'], seed=536131300, status='succeeded', trained_tokens=10521, training_file='file-aRcuFvUVcDiFlTLuJ2zuOf42', validation_file='file-l4XN9lwDjLRdfH1yhQammB2N', estimated_finish=None, integrations=[], user_provided_suffix='marv-ft-0001'), FineTuningJob(id='ftjob-oeBH71kUoI5hSabOiCH8k3zS', created_at=1723342337, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal::9usUfA4b', finished_at=1723342867, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-SQH2HT1IvRszon9pdYwV1yvQ', result_files=['file-MKuwPqztlJBlr0fpe3rf08vb'], seed=1413879039, status='succeeded', trained_tokens=10521, training_file='file-aRcuFvUVcDiFlTLuJ2zuOf42', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None), FineTuningJob(id='ftjob-CRVtbKaFJ8mJBraHDHzfezi8', created_at=1723045253, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal:sports-headlines:9tdBiJmI', finished_at=1723045705, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-SQH2HT1IvRszon9pdYwV1yvQ', result_files=['file-meoIx1LM97AFWXhOah1X7pPc'], seed=732679730, status='succeeded', trained_tokens=94380, training_file='file-PtYnjLIzYW3EB6pm2t11A6fl', validation_file='file-tE8u2fjmTeFZKZTPZccQ6aSn', estimated_finish=None, integrations=[], user_provided_suffix='sports_headlines'), FineTuningJob(id='ftjob-Nyik8wkNII2YoWMtk5cIsqM7', created_at=1723009222, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal:sports-headlines:9tTnzbWX', finished_at=1723009638, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-SQH2HT1IvRszon9pdYwV1yvQ', result_files=['file-d9wyAJIP0tOdejjAe818isy2'], seed=724605458, status='succeeded', trained_tokens=94380, training_file='file-PtYnjLIzYW3EB6pm2t11A6fl', validation_file='file-tE8u2fjmTeFZKZTPZccQ6aSn', estimated_finish=None, integrations=[], user_provided_suffix='sports_headlines'), FineTuningJob(id='ftjob-QRBP5PMMaunkG3stIP3JKy3D', created_at=1723009217, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal:sports-headlines:9tTsvgvm', finished_at=1723009944, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-SQH2HT1IvRszon9pdYwV1yvQ', result_files=['file-cUJxElG7NTDS2JFhE6fxP6iQ'], seed=1490639288, status='succeeded', trained_tokens=94380, training_file='file-PtYnjLIzYW3EB6pm2t11A6fl', validation_file='file-tE8u2fjmTeFZKZTPZccQ6aSn', estimated_finish=None, integrations=[], user_provided_suffix='sports_headlines'), FineTuningJob(id='ftjob-IXlkUz9Arr7OwcioV5sInNZc', created_at=1723002010, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal:sports-headlines:9tRwJJDz', finished_at=1723002466, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-SQH2HT1IvRszon9pdYwV1yvQ', result_files=['file-WhkblhcTjdPMf3vYj0iB3na5'], seed=429565763, status='succeeded', trained_tokens=94380, training_file='file-PtYnjLIzYW3EB6pm2t11A6fl', validation_file='file-tE8u2fjmTeFZKZTPZccQ6aSn', estimated_finish=None, integrations=[], user_provided_suffix='sports_headlines'), FineTuningJob(id='ftjob-Cta6HSxQEq6BKIS69I791jiw', created_at=1722987599, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal:sports-headlines:9tOEVbg0', finished_at=1722988218, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-SQH2HT1IvRszon9pdYwV1yvQ', result_files=['file-nyly3ojaV8AkC0zGNiCm2pJp'], seed=311697236, status='succeeded', trained_tokens=94380, training_file='file-PtYnjLIzYW3EB6pm2t11A6fl', validation_file='file-tE8u2fjmTeFZKZTPZccQ6aSn', estimated_finish=None, integrations=[], user_provided_suffix='sports_headlines'), FineTuningJob(id='ftjob-RfIjCVMhQu4IqJrOMHJKnKJC', created_at=1722987593, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal:sports-headlines:9tOEEB4M', finished_at=1722988200, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-SQH2HT1IvRszon9pdYwV1yvQ', result_files=['file-fjUomRwV0eKrJXX9UDJ4qn4H'], seed=1761117889, status='succeeded', trained_tokens=94380, training_file='file-PtYnjLIzYW3EB6pm2t11A6fl', validation_file='file-tE8u2fjmTeFZKZTPZccQ6aSn', estimated_finish=None, integrations=[], user_provided_suffix='sports_headlines'), FineTuningJob(id='ftjob-LSnA15L6lyVC1SKzPcBjalcK', created_at=1722980386, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal:sports-headlines:9tMIx6Qa', finished_at=1722980806, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-SQH2HT1IvRszon9pdYwV1yvQ', result_files=['file-hARFVMRmipN8D9CwUSRffe75'], seed=590255074, status='succeeded', trained_tokens=94380, training_file='file-PtYnjLIzYW3EB6pm2t11A6fl', validation_file='file-tE8u2fjmTeFZKZTPZccQ6aSn', estimated_finish=None, integrations=[], user_provided_suffix='sports_headlines'), FineTuningJob(id='ftjob-rbSxX1ZOeSaKgoyPfRqMwOSQ', created_at=1722980384, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal:sports-headlines:9tMJOOcb', finished_at=1722980833, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-SQH2HT1IvRszon9pdYwV1yvQ', result_files=['file-E2tbhzmZmIvj4wcBBEf5eIWR'], seed=1672947192, status='succeeded', trained_tokens=94380, training_file='file-PtYnjLIzYW3EB6pm2t11A6fl', validation_file='file-tE8u2fjmTeFZKZTPZccQ6aSn', estimated_finish=None, integrations=[], user_provided_suffix='sports_headlines'), FineTuningJob(id='ftjob-anNKbMy98mQixA6wlkbC9Z01', created_at=1722980381, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal:sports-headlines:9tMJOD1q', finished_at=1722980832, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-SQH2HT1IvRszon9pdYwV1yvQ', result_files=['file-GFOCeQtucvhZlBbbE0ySdPE9'], seed=2110776483, status='succeeded', trained_tokens=94380, training_file='file-PtYnjLIzYW3EB6pm2t11A6fl', validation_file='file-tE8u2fjmTeFZKZTPZccQ6aSn', estimated_finish=None, integrations=[], user_provided_suffix='sports_headlines'), FineTuningJob(id='ftjob-yPHMy4j6mlaaKFWzi2Aegzsq', created_at=1722965968, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal:sports-headlines:9tIYLaub', finished_at=1722966383, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-SQH2HT1IvRszon9pdYwV1yvQ', result_files=['file-aFrpeXPsE75u9JhkbUSti8lJ'], seed=1136127364, status='succeeded', trained_tokens=94380, training_file='file-PtYnjLIzYW3EB6pm2t11A6fl', validation_file='file-tE8u2fjmTeFZKZTPZccQ6aSn', estimated_finish=None, integrations=[], user_provided_suffix='sports_headlines'), FineTuningJob(id='ftjob-WOaYSeUyjiaiC3phHdXl4WIm', created_at=1722958753, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal:sports-headlines:9tGjWYHA', finished_at=1722959389, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-SQH2HT1IvRszon9pdYwV1yvQ', result_files=['file-pQ57f1ZzrueirAe3pxHhHtnz'], seed=61105657, status='succeeded', trained_tokens=94380, training_file='file-PtYnjLIzYW3EB6pm2t11A6fl', validation_file='file-tE8u2fjmTeFZKZTPZccQ6aSn', estimated_finish=None, integrations=[], user_provided_suffix='sports_headlines'), FineTuningJob(id='ftjob-I65O4UwSEZr0e70uTwCW4AJk', created_at=1722918298, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-SQH2HT1IvRszon9pdYwV1yvQ', result_files=[], seed=1272074906, status='cancelled', trained_tokens=None, training_file='file-o8n58Jlfdqhgq3ItjNbHbB8o', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix='dead_walking')], object='list', has_more=True)\n",
      "\n",
      "\n",
      "ftjob-WcdcO2exERwuEIK1fEcM2JBT fine_tuning.job succeeded\n",
      "ftjob-ueWCuRQ1x3VqEXRAjJ6Kv5Oa fine_tuning.job succeeded\n",
      "ftjob-ZjHbXqe1ficE0kvMy7RxfJrE fine_tuning.job succeeded\n",
      "ftjob-iNtCqKhdZUJ583nxlavNW3OW fine_tuning.job succeeded\n",
      "ftjob-1SJhNwARrgon5LLTLnqG4Dvx fine_tuning.job succeeded\n",
      "ftjob-V9xgWRDss6V3gp1jpybSXHdn fine_tuning.job succeeded\n",
      "ftjob-iSjFrat8Pcfeyug3kwL2FM9M fine_tuning.job succeeded\n",
      "ftjob-oeBH71kUoI5hSabOiCH8k3zS fine_tuning.job succeeded\n",
      "ftjob-CRVtbKaFJ8mJBraHDHzfezi8 fine_tuning.job succeeded\n",
      "ftjob-Nyik8wkNII2YoWMtk5cIsqM7 fine_tuning.job succeeded\n",
      "ftjob-QRBP5PMMaunkG3stIP3JKy3D fine_tuning.job succeeded\n",
      "ftjob-IXlkUz9Arr7OwcioV5sInNZc fine_tuning.job succeeded\n",
      "ftjob-Cta6HSxQEq6BKIS69I791jiw fine_tuning.job succeeded\n",
      "ftjob-RfIjCVMhQu4IqJrOMHJKnKJC fine_tuning.job succeeded\n",
      "ftjob-LSnA15L6lyVC1SKzPcBjalcK fine_tuning.job succeeded\n",
      "ftjob-rbSxX1ZOeSaKgoyPfRqMwOSQ fine_tuning.job succeeded\n",
      "ftjob-anNKbMy98mQixA6wlkbC9Z01 fine_tuning.job succeeded\n",
      "ftjob-yPHMy4j6mlaaKFWzi2Aegzsq fine_tuning.job succeeded\n",
      "ftjob-WOaYSeUyjiaiC3phHdXl4WIm fine_tuning.job succeeded\n",
      "ftjob-I65O4UwSEZr0e70uTwCW4AJk fine_tuning.job cancelled\n",
      "\n",
      "\n",
      "\n",
      "Job ID: ftjob-WcdcO2exERwuEIK1fEcM2JBT\n",
      "Created At: 1723400659\n",
      "Error: Error(code=None, message=None, param=None)\n",
      "Fine-tuned Model: ft:gpt-4o-mini-2024-07-18:personal:marv-wandb-tune:9v7hfQoT\n",
      "Finished At: 1723401333\n",
      "Hyperparameters:\n",
      "    - Epochs: 3\n",
      "    - Batch Size: 1\n",
      "    - Learning Rate Multiplier: 1.8\n",
      "Model: gpt-4o-mini-2024-07-18\n",
      "Object: fine_tuning.job\n",
      "Organization ID: org-SQH2HT1IvRszon9pdYwV1yvQ\n",
      "Result Files: file-9rvOEZkwsslSW94AI2J0GcBU\n",
      "Seed: 32159879\n",
      "Status: succeeded\n",
      "Trained Tokens: 10542\n",
      "Training File: file-oeSDEG9qQLA9aGSL3wN8yLsO\n",
      "Validation File: file-4sbdIBCMl6yGsqIpVrjmuA0c\n",
      "Estimated Finish: None\n",
      "Integrations: FineTuningJobWandbIntegrationObject(type='wandb', wandb=FineTuningJobWandbIntegration(project='Marv_Fun_Tune_v2', entity='suspicious-cow-self', name=None, tags=None, run_id='ftjob-WcdcO2exERwuEIK1fEcM2JBT'))\n",
      "User Provided Suffix: marv_wandb_tune\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# list our fine-tuning jobs\n",
    "ft_jobs_list = client.fine_tuning.jobs.list()\n",
    "\n",
    "print(ft_jobs_list)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Print job IDs, objects, and statuses\n",
    "for job in ft_jobs_list.data:\n",
    "    print(job.id, job.object, job.status)\n",
    "\n",
    "\n",
    "# Print detailed information for only the first job in the list\n",
    "job = ft_jobs_list.data[0]\n",
    "\n",
    "print(\"\\n\")\n",
    "print(f\"\"\"\n",
    "Job ID: {job.id}\n",
    "Created At: {job.created_at}\n",
    "Error: {job.error}\n",
    "Fine-tuned Model: {job.fine_tuned_model}\n",
    "Finished At: {job.finished_at}\n",
    "Hyperparameters:\n",
    "    - Epochs: {job.hyperparameters.n_epochs}\n",
    "    - Batch Size: {job.hyperparameters.batch_size}\n",
    "    - Learning Rate Multiplier: {job.hyperparameters.learning_rate_multiplier}\n",
    "Model: {job.model}\n",
    "Object: {job.object}\n",
    "Organization ID: {job.organization_id}\n",
    "Result Files: {', '.join(str(file) for file in job.result_files)}\n",
    "Seed: {job.seed}\n",
    "Status: {job.status}\n",
    "Trained Tokens: {job.trained_tokens}\n",
    "Training File: {job.training_file}\n",
    "Validation File: {job.validation_file}\n",
    "Estimated Finish: {job.estimated_finish}\n",
    "Integrations: {', '.join(str(integration) for integration in job.integrations) if job.integrations else 'None'}\n",
    "User Provided Suffix: {job.user_provided_suffix}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving Fine-Tuning Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "retrieved_job ID: ftjob-WcdcO2exERwuEIK1fEcM2JBT\n",
      "Created At: 1723400659\n",
      "Error: Error(code=None, message=None, param=None)\n",
      "Fine-tuned Model: ft:gpt-4o-mini-2024-07-18:personal:marv-wandb-tune:9v7hfQoT\n",
      "Finished At: 1723401333\n",
      "Hyperparameters:\n",
      "    - Epochs: 3\n",
      "    - Batch Size: 1\n",
      "    - Learning Rate Multiplier: 1.8\n",
      "Model: gpt-4o-mini-2024-07-18\n",
      "Object: fine_tuning.job\n",
      "Organization ID: org-SQH2HT1IvRszon9pdYwV1yvQ\n",
      "Result Files: file-9rvOEZkwsslSW94AI2J0GcBU\n",
      "Seed: 32159879\n",
      "Status: succeeded\n",
      "Trained Tokens: 10542\n",
      "Training File: file-oeSDEG9qQLA9aGSL3wN8yLsO\n",
      "Validation File: file-4sbdIBCMl6yGsqIpVrjmuA0c\n",
      "Estimated Finish: None\n",
      "Integrations: FineTuningJobWandbIntegrationObject(type='wandb', wandb=FineTuningJobWandbIntegration(project='Marv_Fun_Tune_v2', entity='suspicious-cow-self', name=None, tags=None, run_id='ftjob-WcdcO2exERwuEIK1fEcM2JBT'))\n",
      "User Provided Suffix: marv_wandb_tune\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the fine-tuning job by ID\n",
    "retrieved_job = client.fine_tuning.jobs.retrieve(job.id)\n",
    "\n",
    "print(f\"\"\"\n",
    "retrieved_job ID: {retrieved_job.id}\n",
    "Created At: {retrieved_job.created_at}\n",
    "Error: {retrieved_job.error}\n",
    "Fine-tuned Model: {retrieved_job.fine_tuned_model}\n",
    "Finished At: {retrieved_job.finished_at}\n",
    "Hyperparameters:\n",
    "    - Epochs: {retrieved_job.hyperparameters.n_epochs}\n",
    "    - Batch Size: {retrieved_job.hyperparameters.batch_size}\n",
    "    - Learning Rate Multiplier: {retrieved_job.hyperparameters.learning_rate_multiplier}\n",
    "Model: {retrieved_job.model}\n",
    "Object: {retrieved_job.object}\n",
    "Organization ID: {retrieved_job.organization_id}\n",
    "Result Files: {', '.join(str(file) for file in job.result_files)}\n",
    "Seed: {retrieved_job.seed}\n",
    "Status: {retrieved_job.status}\n",
    "Trained Tokens: {retrieved_job.trained_tokens}\n",
    "Training File: {retrieved_job.training_file}\n",
    "Validation File: {retrieved_job.validation_file}\n",
    "Estimated Finish: {retrieved_job.estimated_finish}\n",
    "Integrations: {', '.join(str(integration) for integration in job.integrations) if job.integrations else 'None'}\n",
    "User Provided Suffix: {retrieved_job.user_provided_suffix}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Checkpoints\n",
    "\n",
    "### Listing Job Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncCursorPage[FineTuningJobCheckpoint](data=[FineTuningJobCheckpoint(id='ftckpt_RLf3ZqwahdDD2iT4otJErkRr', created_at=1723389359, fine_tuned_model_checkpoint='ft:gpt-4o-mini-2024-07-18:personal:marv-ft-0003:9v4b4nlv', fine_tuning_job_id='ftjob-iNtCqKhdZUJ583nxlavNW3OW', metrics=Metrics(full_valid_loss=None, full_valid_mean_token_accuracy=None, step=240.0, train_loss=0.0005891973269172013, train_mean_token_accuracy=1.0, valid_loss=0.879476819719587, valid_mean_token_accuracy=0.7142857142857143), object='fine_tuning.job.checkpoint', step_number=240), FineTuningJobCheckpoint(id='ftckpt_Ig4cmKuYHDJO82NrANrGhj2i', created_at=1723389228, fine_tuned_model_checkpoint='ft:gpt-4o-mini-2024-07-18:personal:marv-ft-0003:9v4b4DyO:ckpt-step-160', fine_tuning_job_id='ftjob-iNtCqKhdZUJ583nxlavNW3OW', metrics=Metrics(full_valid_loss=None, full_valid_mean_token_accuracy=None, step=160.0, train_loss=0.4574517607688904, train_mean_token_accuracy=0.9230769276618958, valid_loss=1.620632318349985, valid_mean_token_accuracy=0.7692307692307693), object='fine_tuning.job.checkpoint', step_number=160), FineTuningJobCheckpoint(id='ftckpt_tq0mlQcyymTNzoc3KJ2BhkNM', created_at=1723389089, fine_tuned_model_checkpoint='ft:gpt-4o-mini-2024-07-18:personal:marv-ft-0003:9v4b4tuF:ckpt-step-80', fine_tuning_job_id='ftjob-iNtCqKhdZUJ583nxlavNW3OW', metrics=Metrics(full_valid_loss=None, full_valid_mean_token_accuracy=None, step=80.0, train_loss=0.736206591129303, train_mean_token_accuracy=0.7272727489471436, valid_loss=1.2090108871459961, valid_mean_token_accuracy=0.8), object='fine_tuning.job.checkpoint', step_number=80)], object='list', has_more=False, first_id='ftckpt_RLf3ZqwahdDD2iT4otJErkRr', last_id='ftckpt_tq0mlQcyymTNzoc3KJ2BhkNM')\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint ID:  ftckpt_RLf3ZqwahdDD2iT4otJErkRr \n",
      " Fine-tuned Model Checkpoint:  ft:gpt-4o-mini-2024-07-18:personal:marv-ft-0003:9v4b4nlv \n",
      " Step Number:  240 \n",
      " Created At:  1723389359 \n",
      " Training Loss:  0.0005891973269172013 \n",
      " Validation Loss:  0.879476819719587 \n",
      " Fine-tuning Job ID:  ftjob-iNtCqKhdZUJ583nxlavNW3OW \n",
      "\n",
      "Checkpoint ID:  ftckpt_Ig4cmKuYHDJO82NrANrGhj2i \n",
      " Fine-tuned Model Checkpoint:  ft:gpt-4o-mini-2024-07-18:personal:marv-ft-0003:9v4b4DyO:ckpt-step-160 \n",
      " Step Number:  160 \n",
      " Created At:  1723389228 \n",
      " Training Loss:  0.4574517607688904 \n",
      " Validation Loss:  1.620632318349985 \n",
      " Fine-tuning Job ID:  ftjob-iNtCqKhdZUJ583nxlavNW3OW \n",
      "\n",
      "Checkpoint ID:  ftckpt_tq0mlQcyymTNzoc3KJ2BhkNM \n",
      " Fine-tuned Model Checkpoint:  ft:gpt-4o-mini-2024-07-18:personal:marv-ft-0003:9v4b4tuF:ckpt-step-80 \n",
      " Step Number:  80 \n",
      " Created At:  1723389089 \n",
      " Training Loss:  0.736206591129303 \n",
      " Validation Loss:  1.2090108871459961 \n",
      " Fine-tuning Job ID:  ftjob-iNtCqKhdZUJ583nxlavNW3OW \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List all fine-tuning job checkpoints\n",
    "ft_jobs_checkpoints_list = client.fine_tuning.jobs.checkpoints.list(all_params_ft_job.id)\n",
    "\n",
    "# Print the entire list of checkpoints\n",
    "print(ft_jobs_checkpoints_list)\n",
    "print(\"\\n\\n\")  # Add two blank lines for better readability\n",
    "\n",
    "# Iterate through each checkpoint and print specific details\n",
    "for checkpoint in ft_jobs_checkpoints_list:\n",
    "    print(\"Checkpoint ID: \", checkpoint.id, \"\\n\",                        # Unique identifier for the checkpoint\n",
    "        \"Fine-tuned Model Checkpoint: \", checkpoint.fine_tuned_model_checkpoint, \"\\n\",  # Checkpoint of the fine-tuned model\n",
    "        \"Step Number: \", checkpoint.step_number, \"\\n\",                # Training step at which checkpoint was saved\n",
    "        \"Created At: \", checkpoint.created_at, \"\\n\",                  # Timestamp of checkpoint creation\n",
    "        \"Training Loss: \", checkpoint.metrics.train_loss, \"\\n\",       # Training loss at this checkpoint\n",
    "        \"Validation Loss: \", checkpoint.metrics.valid_loss, \"\\n\",       # Validation loss at this checkpoint\n",
    "        \"Fine-tuning Job ID: \", checkpoint.fine_tuning_job_id, \"\\n\"   # ID of the associated fine-tuning job\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Fine-tuning Events\n",
    "\n",
    "### List Fine-Tuning Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncCursorPage[FineTuningJobEvent](data=[FineTuningJobEvent(id='ftevent-Tqz5wMQryfFZ9swoEe5nVDbc', created_at=1723389401, level='info', message='The job has successfully completed', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-ITIsz5gfqV8Kkx1NnN1Bs687', created_at=1723389395, level='info', message='New fine-tuned model created: ft:gpt-4o-mini-2024-07-18:personal:marv-ft-0003:9v4b4nlv', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-cfOMQrpKLekrCF406MhluXay', created_at=1723389395, level='info', message='Checkpoint created at step 160 with Snapshot ID: ft:gpt-4o-mini-2024-07-18:personal:marv-ft-0003:9v4b4DyO:ckpt-step-160', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-TpucuRtX4ZnmfwWXQnNhUJL9', created_at=1723389395, level='info', message='Checkpoint created at step 80 with Snapshot ID: ft:gpt-4o-mini-2024-07-18:personal:marv-ft-0003:9v4b4tuF:ckpt-step-80', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-yxxmt6y20V92UKiWR4Yv3q5A', created_at=1723389382, level='info', message='Step 240/240: training loss=0.00, validation loss=0.88, full validation loss=1.34', object='fine_tuning.job.event', data={'step': 240, 'train_loss': 0.0005891973269172013, 'valid_loss': 0.879476819719587, 'total_steps': 240, 'full_valid_loss': 1.339357952043122, 'train_mean_token_accuracy': 1.0, 'valid_mean_token_accuracy': 0.7142857142857143, 'full_valid_mean_token_accuracy': 0.7686274509803922}, type='metrics'), FineTuningJobEvent(id='ftevent-ZBixS2Bj4WxrHsFMobHseEgd', created_at=1723389351, level='info', message='Step 239/240: training loss=0.20', object='fine_tuning.job.event', data={'step': 239, 'train_loss': 0.1976538449525833, 'total_steps': 240, 'train_mean_token_accuracy': 0.9230769276618958}, type='metrics'), FineTuningJobEvent(id='ftevent-2GCu7urymDxRubQBqrifqmNx', created_at=1723389348, level='info', message='Step 238/240: training loss=0.01', object='fine_tuning.job.event', data={'step': 238, 'train_loss': 0.013896605931222439, 'total_steps': 240, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-SM4V54DBRMotK0OoN5QEdzdZ', created_at=1723389348, level='info', message='Step 237/240: training loss=0.14', object='fine_tuning.job.event', data={'step': 237, 'train_loss': 0.14377529919147491, 'total_steps': 240, 'train_mean_token_accuracy': 0.9444444179534912}, type='metrics'), FineTuningJobEvent(id='ftevent-yP9YXeugFGdyScSGkZDHh8jK', created_at=1723389348, level='info', message='Step 236/240: training loss=0.51', object='fine_tuning.job.event', data={'step': 236, 'train_loss': 0.5139821767807007, 'total_steps': 240, 'train_mean_token_accuracy': 0.8461538553237915}, type='metrics'), FineTuningJobEvent(id='ftevent-uoiUfrYWa95sA9uX4sVEp5VC', created_at=1723389348, level='info', message='Step 235/240: training loss=0.00', object='fine_tuning.job.event', data={'step': 235, 'train_loss': 0.0027188195381313562, 'total_steps': 240, 'train_mean_token_accuracy': 1.0}, type='metrics')], object='list', has_more=True)\n",
      "\n",
      "\n",
      "\n",
      "Event ID:  ftevent-Tqz5wMQryfFZ9swoEe5nVDbc \n",
      " Object Type:  fine_tuning.job.event \n",
      " Created At:  1723389401 \n",
      " Level:  info \n",
      " Type:  message \n",
      " Message:  The job has successfully completed \n",
      "\n",
      "Event ID:  ftevent-ITIsz5gfqV8Kkx1NnN1Bs687 \n",
      " Object Type:  fine_tuning.job.event \n",
      " Created At:  1723389395 \n",
      " Level:  info \n",
      " Type:  message \n",
      " Message:  New fine-tuned model created: ft:gpt-4o-mini-2024-07-18:personal:marv-ft-0003:9v4b4nlv \n",
      "\n",
      "Event ID:  ftevent-cfOMQrpKLekrCF406MhluXay \n",
      " Object Type:  fine_tuning.job.event \n",
      " Created At:  1723389395 \n",
      " Level:  info \n",
      " Type:  message \n",
      " Message:  Checkpoint created at step 160 with Snapshot ID: ft:gpt-4o-mini-2024-07-18:personal:marv-ft-0003:9v4b4DyO:ckpt-step-160 \n",
      "\n",
      "Event ID:  ftevent-TpucuRtX4ZnmfwWXQnNhUJL9 \n",
      " Object Type:  fine_tuning.job.event \n",
      " Created At:  1723389395 \n",
      " Level:  info \n",
      " Type:  message \n",
      " Message:  Checkpoint created at step 80 with Snapshot ID: ft:gpt-4o-mini-2024-07-18:personal:marv-ft-0003:9v4b4tuF:ckpt-step-80 \n",
      "\n",
      "Event ID:  ftevent-yxxmt6y20V92UKiWR4Yv3q5A \n",
      " Object Type:  fine_tuning.job.event \n",
      " Created At:  1723389382 \n",
      " Level:  info \n",
      " Type:  metrics \n",
      " Message:  Step 240/240: training loss=0.00, validation loss=0.88, full validation loss=1.34 \n",
      "\n",
      "Event ID:  ftevent-ZBixS2Bj4WxrHsFMobHseEgd \n",
      " Object Type:  fine_tuning.job.event \n",
      " Created At:  1723389351 \n",
      " Level:  info \n",
      " Type:  metrics \n",
      " Message:  Step 239/240: training loss=0.20 \n",
      "\n",
      "Event ID:  ftevent-2GCu7urymDxRubQBqrifqmNx \n",
      " Object Type:  fine_tuning.job.event \n",
      " Created At:  1723389348 \n",
      " Level:  info \n",
      " Type:  metrics \n",
      " Message:  Step 238/240: training loss=0.01 \n",
      "\n",
      "Event ID:  ftevent-SM4V54DBRMotK0OoN5QEdzdZ \n",
      " Object Type:  fine_tuning.job.event \n",
      " Created At:  1723389348 \n",
      " Level:  info \n",
      " Type:  metrics \n",
      " Message:  Step 237/240: training loss=0.14 \n",
      "\n",
      "Event ID:  ftevent-yP9YXeugFGdyScSGkZDHh8jK \n",
      " Object Type:  fine_tuning.job.event \n",
      " Created At:  1723389348 \n",
      " Level:  info \n",
      " Type:  metrics \n",
      " Message:  Step 236/240: training loss=0.51 \n",
      "\n",
      "Event ID:  ftevent-uoiUfrYWa95sA9uX4sVEp5VC \n",
      " Object Type:  fine_tuning.job.event \n",
      " Created At:  1723389348 \n",
      " Level:  info \n",
      " Type:  metrics \n",
      " Message:  Step 235/240: training loss=0.00 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List the events for the first fine-tuning job in our list\n",
    "ft_events_list = client.fine_tuning.jobs.list_events(\n",
    "    fine_tuning_job_id=all_params_ft_job.id,\n",
    "    limit=10  # Limit the number of events to retrieve\n",
    ")\n",
    "\n",
    "# Print the entire list of events\n",
    "print(ft_events_list)\n",
    "print(\"\\n\\n\")  # Add two blank lines for better readability\n",
    "\n",
    "# Iterate through each event and print specific details\n",
    "for event in ft_events_list.data:\n",
    "    print(\"Event ID: \", event.id, \"\\n\",             # Unique identifier for the event\n",
    "        \"Object Type: \", event.object, \"\\n\",      # Type of object (likely 'fine_tuning.job.event')\n",
    "        \"Created At: \", event.created_at, \"\\n\",   # Timestamp when the event was created\n",
    "        \"Level: \", event.level, \"\\n\",             # Importance level of the event (e.g., 'info', 'warning')\n",
    "        \"Type: \", event.type, \"\\n\",               # Type of event\n",
    "        \"Message: \", event.message, \"\\n\"          # Descriptive message about the event\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cancelling Fine-Tuning Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status after cancellation: cancelled\n"
     ]
    }
   ],
   "source": [
    "# Create a fine-tuning job using the uploaded training data\n",
    "dead_ft_job_walking = client.fine_tuning.jobs.create(\n",
    "        model=\"gpt-3.5-turbo-0125\",\n",
    "        training_file=train__set_file.id, \n",
    "        validation_file=None,\n",
    "        hyperparameters={\n",
    "            \"batch_size\": \"auto\",\n",
    "            \"learning_rate_multiplier\": \"auto\",\n",
    "            \"n_epochs\": \"auto\",\n",
    "        },\n",
    "        suffix=\"dead_walking\",\n",
    "        integrations=None,\n",
    "        seed=None,\n",
    "    )\n",
    "\n",
    "# Cancel the fine-tuning job\n",
    "client.fine_tuning.jobs.cancel(dead_ft_job_walking.id)\n",
    "\n",
    "# Retrieve the fine-tuning job by ID and show the updated status\n",
    "dead_ft_job_walking_status = client.fine_tuning.jobs.retrieve(dead_ft_job_walking.id)\n",
    "\n",
    "print(f\"Job status after cancellation: {dead_ft_job_walking_status.status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Fine-Tuned Models\n",
    "\n",
    "### Using Fine-Tuned Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== All Jobs =====\n",
      "ftjob-4DjQalMlp0Ua7Mbciu593HmZ fine_tuning.job cancelled\n",
      "ftjob-WcdcO2exERwuEIK1fEcM2JBT fine_tuning.job succeeded\n",
      "ftjob-ueWCuRQ1x3VqEXRAjJ6Kv5Oa fine_tuning.job succeeded\n",
      "ftjob-ZjHbXqe1ficE0kvMy7RxfJrE fine_tuning.job succeeded\n",
      "ftjob-iNtCqKhdZUJ583nxlavNW3OW fine_tuning.job succeeded\n",
      "ftjob-1SJhNwARrgon5LLTLnqG4Dvx fine_tuning.job succeeded\n",
      "ftjob-V9xgWRDss6V3gp1jpybSXHdn fine_tuning.job succeeded\n",
      "ftjob-iSjFrat8Pcfeyug3kwL2FM9M fine_tuning.job succeeded\n",
      "ftjob-oeBH71kUoI5hSabOiCH8k3zS fine_tuning.job succeeded\n",
      "ftjob-CRVtbKaFJ8mJBraHDHzfezi8 fine_tuning.job succeeded\n",
      "ftjob-Nyik8wkNII2YoWMtk5cIsqM7 fine_tuning.job succeeded\n",
      "ftjob-QRBP5PMMaunkG3stIP3JKy3D fine_tuning.job succeeded\n",
      "ftjob-IXlkUz9Arr7OwcioV5sInNZc fine_tuning.job succeeded\n",
      "ftjob-Cta6HSxQEq6BKIS69I791jiw fine_tuning.job succeeded\n",
      "ftjob-RfIjCVMhQu4IqJrOMHJKnKJC fine_tuning.job succeeded\n",
      "ftjob-LSnA15L6lyVC1SKzPcBjalcK fine_tuning.job succeeded\n",
      "ftjob-rbSxX1ZOeSaKgoyPfRqMwOSQ fine_tuning.job succeeded\n",
      "ftjob-anNKbMy98mQixA6wlkbC9Z01 fine_tuning.job succeeded\n",
      "ftjob-yPHMy4j6mlaaKFWzi2Aegzsq fine_tuning.job succeeded\n",
      "ftjob-WOaYSeUyjiaiC3phHdXl4WIm fine_tuning.job succeeded\n",
      "ftjob-I65O4UwSEZr0e70uTwCW4AJk fine_tuning.job cancelled\n",
      "ftjob-dbc3yF9edvpeGj6STVOqqT79 fine_tuning.job succeeded\n",
      "ftjob-D3Yfr2qfvqsT7CpwBHosRo7i fine_tuning.job succeeded\n",
      "ftjob-In4Gwg2ZvNaae6qDmqCpGADT fine_tuning.job succeeded\n",
      "ftjob-xQ1a623wHKnW57koV7UUC5bv fine_tuning.job succeeded\n",
      "ftjob-WPnURlgsSvMEFQBYo5LdUp9P fine_tuning.job succeeded\n",
      "ftjob-Et16UfmszRbg1Sx0Iy6C6w2A fine_tuning.job cancelled\n",
      "ftjob-TcnaEQtuuDAIGgqB0ws4d6MW fine_tuning.job succeeded\n",
      "ftjob-9f6ZQDTbvGa6hP3a0H9DzVl3 fine_tuning.job succeeded\n",
      "ftjob-YyUHxmAy8mEjySIyPSODD11Z fine_tuning.job succeeded\n",
      "ftjob-1umw7WOdBKvdGjrYYRQmNii7 fine_tuning.job succeeded\n",
      "ftjob-o7cb0nZN7dv9I5WaDb87duHB fine_tuning.job succeeded\n",
      "ftjob-SOm5WUO0ERuV9qJohvO8qwub fine_tuning.job succeeded\n",
      "ftjob-RZy4xJ53k6sdbQdJuH0jwNui fine_tuning.job succeeded\n",
      "ftjob-FTbeMMyTx2b68qFf15S43wgk fine_tuning.job succeeded\n",
      "ftjob-PsOilXGO8pUPel7ShmniRGx0 fine_tuning.job cancelled\n",
      "ftjob-IQ1jEklydQL5JkIH5gk7grYF fine_tuning.job cancelled\n",
      "ftjob-FnNLMHfUaYnmNxVn5ZiWB5Xt fine_tuning.job cancelled\n",
      "ftjob-Sltbyz9ZYawwIujUrfoQT7KR fine_tuning.job succeeded\n",
      "ftjob-i9LhkfoWEEGCm9i6TnQTkY6H fine_tuning.job succeeded\n",
      "ftjob-XKB9aPeQoPzLx5Y6YCrtuNk4 fine_tuning.job succeeded\n",
      "ftjob-YQIfWRRVb4F7jeqZxs04KFWX fine_tuning.job succeeded\n",
      "ftjob-Kdb7GyO9S87uB6PX62MwrKtR fine_tuning.job succeeded\n",
      "ftjob-euOWwmWdcXLDm64ljgfebLms fine_tuning.job succeeded\n",
      "ftjob-H4DMxhPi0gsK0MeVbG0KYTkC fine_tuning.job succeeded\n",
      "ftjob-Uoqu5d7l88RkE64n74NHWv6T fine_tuning.job cancelled\n",
      "ftjob-KXGcxmec50aWpHgW2inr46a0 fine_tuning.job succeeded\n",
      "ftjob-u80489e0PhlOlXoYq8whtTLd fine_tuning.job succeeded\n",
      "ftjob-PltdPhHtGnGsHQsr5yCrYWtE fine_tuning.job cancelled\n",
      "ftjob-orahseqw77QkzMQi4Tup35ne fine_tuning.job cancelled\n",
      "ftjob-DYtxvX2JLR63STsEftN0BOUz fine_tuning.job cancelled\n",
      "ftjob-FP8hhoeoz2VNMErGLC2l08lj fine_tuning.job cancelled\n",
      "ftjob-IeZqMInAmyrjiG560lC2DyhC fine_tuning.job cancelled\n",
      "ftjob-8UQfKJAbJGczYczkUNq1vp9u fine_tuning.job cancelled\n",
      "ftjob-Plkvlwrt3NEBYB6Skwc9xaho fine_tuning.job cancelled\n",
      "ftjob-LAdn53Pv0uLlSNZMTnCKWStO fine_tuning.job cancelled\n",
      "ftjob-yaw0xXr5pUqIv4aLWmmlItSP fine_tuning.job cancelled\n",
      "ftjob-gMDEfH6i7VN2FezNwGSnJH9W fine_tuning.job succeeded\n",
      "ftjob-OHgkMsoSksrEt0cV04mef81l fine_tuning.job succeeded\n",
      "ftjob-G00quADKnXQGp0ASXpwp17Cg fine_tuning.job succeeded\n",
      "\n",
      "\n",
      "===== Successful Jobs =====\n",
      "ftjob-WcdcO2exERwuEIK1fEcM2JBT fine_tuning.job succeeded\n",
      "ftjob-ueWCuRQ1x3VqEXRAjJ6Kv5Oa fine_tuning.job succeeded\n",
      "ftjob-ZjHbXqe1ficE0kvMy7RxfJrE fine_tuning.job succeeded\n",
      "ftjob-iNtCqKhdZUJ583nxlavNW3OW fine_tuning.job succeeded\n",
      "ftjob-1SJhNwARrgon5LLTLnqG4Dvx fine_tuning.job succeeded\n",
      "ftjob-V9xgWRDss6V3gp1jpybSXHdn fine_tuning.job succeeded\n",
      "ftjob-iSjFrat8Pcfeyug3kwL2FM9M fine_tuning.job succeeded\n",
      "ftjob-oeBH71kUoI5hSabOiCH8k3zS fine_tuning.job succeeded\n",
      "ftjob-CRVtbKaFJ8mJBraHDHzfezi8 fine_tuning.job succeeded\n",
      "ftjob-Nyik8wkNII2YoWMtk5cIsqM7 fine_tuning.job succeeded\n",
      "ftjob-QRBP5PMMaunkG3stIP3JKy3D fine_tuning.job succeeded\n",
      "ftjob-IXlkUz9Arr7OwcioV5sInNZc fine_tuning.job succeeded\n",
      "ftjob-Cta6HSxQEq6BKIS69I791jiw fine_tuning.job succeeded\n",
      "ftjob-RfIjCVMhQu4IqJrOMHJKnKJC fine_tuning.job succeeded\n",
      "ftjob-LSnA15L6lyVC1SKzPcBjalcK fine_tuning.job succeeded\n",
      "ftjob-rbSxX1ZOeSaKgoyPfRqMwOSQ fine_tuning.job succeeded\n",
      "ftjob-anNKbMy98mQixA6wlkbC9Z01 fine_tuning.job succeeded\n",
      "ftjob-yPHMy4j6mlaaKFWzi2Aegzsq fine_tuning.job succeeded\n",
      "ftjob-WOaYSeUyjiaiC3phHdXl4WIm fine_tuning.job succeeded\n"
     ]
    }
   ],
   "source": [
    "# list all our fine-tuning jobs\n",
    "ft_jobs_list = client.fine_tuning.jobs.list()\n",
    "\n",
    "# Print job IDs, objects, and statuses for the filtered list\n",
    "print(\"===== All Jobs =====\")\n",
    "for job in ft_jobs_list:\n",
    "    print(job.id, job.object, job.status)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Filter the list to only include jobs with a status of \"succeeded\"\n",
    "succeeded_jobs_list = [job for job in ft_jobs_list.data if job.status == \"succeeded\"]\n",
    "\n",
    "print(\"===== Successful Jobs =====\")\n",
    "\n",
    "# Print job IDs, objects, and statuses for the filtered list\n",
    "for job in succeeded_jobs_list:\n",
    "    print(job.id, job.object, job.status)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A pungent cheese that smells worse than your gym socks.\n"
     ]
    }
   ],
   "source": [
    "# Use the fine-tuned model to generate a completion\n",
    "completion = client.chat.completions.create(\n",
    "    model=succeeded_jobs_list[0].fine_tuned_model,  # Use the first successful fine-tuned model\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is limburger cheese?\"},\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print the generated response\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Checkpointed Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint ID:  ftckpt_tE1N59IDI5xmehycpoSOEwuk \n",
      " Fine-tuned Model Checkpoint:  ft:gpt-4o-mini-2024-07-18:personal:marv-wandb-tune:9v7hfQoT \n",
      " Step Number:  240 \n",
      " Created At:  1723401300 \n",
      " Training Loss:  0.0022328693885356188 \n",
      " Fine-tuning Job ID:  ftjob-WcdcO2exERwuEIK1fEcM2JBT \n",
      "\n",
      "Checkpoint ID:  ftckpt_YA4ZvnRde7VNlc7fI4k8HBsi \n",
      " Fine-tuned Model Checkpoint:  ft:gpt-4o-mini-2024-07-18:personal:marv-wandb-tune:9v7hfiZn:ckpt-step-160 \n",
      " Step Number:  160 \n",
      " Created At:  1723401150 \n",
      " Training Loss:  0.1336524933576584 \n",
      " Fine-tuning Job ID:  ftjob-WcdcO2exERwuEIK1fEcM2JBT \n",
      "\n",
      "Checkpoint ID:  ftckpt_01FljaJYfZrzv8VsRNq9GsJC \n",
      " Fine-tuned Model Checkpoint:  ft:gpt-4o-mini-2024-07-18:personal:marv-wandb-tune:9v7hetnX:ckpt-step-80 \n",
      " Step Number:  80 \n",
      " Created At:  1723401002 \n",
      " Training Loss:  0.612462043762207 \n",
      " Fine-tuning Job ID:  ftjob-WcdcO2exERwuEIK1fEcM2JBT \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List all fine-tuning job checkpoints for the first successful job\n",
    "ft_jobs_checkpoints_list = client.fine_tuning.jobs.checkpoints.list(\n",
    "    succeeded_jobs_list[0].id  # Use the ID of the first successful job\n",
    ")\n",
    "\n",
    "# Iterate through each checkpoint and print specific details\n",
    "for checkpoint in ft_jobs_checkpoints_list:\n",
    "    print(\"Checkpoint ID: \", checkpoint.id, \"\\n\",                            # Unique identifier for the checkpoint\n",
    "        \"Fine-tuned Model Checkpoint: \", checkpoint.fine_tuned_model_checkpoint, \"\\n\",  # Checkpoint of the fine-tuned model\n",
    "        \"Step Number: \", checkpoint.step_number, \"\\n\",                    # Training step at which checkpoint was saved\n",
    "        \"Created At: \", checkpoint.created_at, \"\\n\",                      # Timestamp of checkpoint creation\n",
    "        \"Training Loss: \", checkpoint.metrics.train_loss, \"\\n\",           # Training loss at this checkpoint\n",
    "        \"Fine-tuning Job ID: \", checkpoint.fine_tuning_job_id, \"\\n\"       # ID of the associated fine-tuning job\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A stinky cheese. Literally. It's known for its strong smell and taste.\n"
     ]
    }
   ],
   "source": [
    "# Get the first checkpoint from the paginated results\n",
    "first_checkpoint = next(iter(ft_jobs_checkpoints_list), None)\n",
    "\n",
    "if first_checkpoint:\n",
    "    # Use the checkpointed model to generate a completion\n",
    "    completion = client.chat.completions.create(\n",
    "        model=first_checkpoint.fine_tuned_model_checkpoint,  # Use the checkpointed model\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"},\n",
    "            {\"role\": \"user\", \"content\": \"What is limburger cheese?\"},\n",
    "        ]\n",
    "    )\n",
    "    # Print the generated response\n",
    "    print(completion.choices[0].message.content)\n",
    "else:\n",
    "    print(\"No checkpoints found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting Fine-Tuned Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete a fine-tuned model\n",
    "# Note: This code is currently commented out\n",
    "\n",
    "# response = client.models.delete(\"ft:gpt-4o-mini-2024-07-18:personal::9rCgzkVh\")\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning Use Cases\n",
    "\n",
    "### Structured Output: Sports Headlines\n",
    "\n",
    "#### Validating Our Data File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 100\n",
      "First example:\n",
      "{'role': 'system', 'content': 'Given a sports headline, provide the following fields in a JSON dict, where applicable: \"player\" (full name), \"team\", \"sport\", and \"gender\".'}\n",
      "{'role': 'user', 'content': 'Lakers sign LeBron James to 2-year contract extension'}\n",
      "{'role': 'assistant', 'content': '{\"player\": \"LeBron James\", \"team\": \"Lakers\", \"sport\": \"basketball\", \"gender\": \"male\" }'}\n",
      "\n",
      "\n",
      "No errors found\n",
      "\n",
      "\n",
      "Summary of dataset processing:\n",
      "Num examples missing system message: 0\n",
      "Num examples missing user message: 0\n",
      "Total number of examples: 100\n",
      "Average number of messages per example: 3.00\n",
      "Average number of total tokens per example: 86.15\n",
      "Average number of assistant tokens per example: 27.48\n",
      "0 examples may be over the 64000 token limit and will be truncated during fine-tuning\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Dataset Statistics:\n",
      "- Number of training examples: 100\n",
      "- Approximate billable tokens: 8615\n",
      "- Default number of epochs: 3\n",
      "- Estimated total billable tokens: 25845\n"
     ]
    }
   ],
   "source": [
    "# Validate the data file that will be used for fine-tuning\n",
    "\n",
    "# Path to the JSONL data file\n",
    "data_path = \"./artifacts/sports_headlines.jsonl\"\n",
    "\n",
    "# Load and print the dataset\n",
    "dataset = load_and_print_dataset(data_path)\n",
    "print(\"\\n\")  # Add a blank line for better readability\n",
    "\n",
    "# Check for format errors in the dataset\n",
    "format_errors = check_format_errors(dataset)\n",
    "print(\"\\n\")  # Add a blank line for better readability\n",
    "\n",
    "# Process the dataset to extract message counts and token lengths\n",
    "n_messages, convo_lens, assistant_message_lens = process_dataset(\n",
    "    dataset, \n",
    "    num_tokens_from_messages, \n",
    "    num_assistant_tokens_from_messages\n",
    ")\n",
    "print(\"\\n\")  # Add a blank line for better readability\n",
    "\n",
    "# Get the total number of examples in the dataset\n",
    "n_train_examples = len(dataset)\n",
    "print(\"\\n\")  # Add a blank line for better readability\n",
    "\n",
    "# Print statistics about the dataset\n",
    "print_dataset_statistics(n_train_examples, convo_lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Train / Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data saved to: artifacts\\sports_headlines_train.jsonl\n",
      "Test data saved to: artifacts\\sports_headlines_test.jsonl\n",
      "Train set size: 80\n",
      "Test set size: 20\n",
      "\n",
      "\n",
      "Train file path: artifacts\\sports_headlines_train.jsonl\n",
      "Test file path: artifacts\\sports_headlines_test.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Split the JSONL file into training and testing sets\n",
    "train_test_files = split_jsonl_file(data_path)\n",
    "print(\"\\n\")  # Add a blank line for better readability\n",
    "\n",
    "# Convert file paths to strings\n",
    "train_path, test_path = [str(file) for file in train_test_files]\n",
    "\n",
    "# Print the paths of the resulting train and test files\n",
    "print(f\"Train file path: {train_path}\")\n",
    "print(f\"Test file path: {test_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload Our Training and Test Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the training data to the OpenAI API\n",
    "sports_headlines_train_file = client.files.create(\n",
    "            file=open(train_path, \"rb\"),\n",
    "            purpose=\"fine-tune\"\n",
    "            )\n",
    "\n",
    "# Upload the training data to the OpenAI API\n",
    "sports_headlines_test_file = client.files.create(\n",
    "            file=open(test_path, \"rb\"),\n",
    "            purpose=\"fine-tune\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit Our Fine-Tuning Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning job created successfully!\n",
      "FineTuningJob(id='ftjob-djbWbqzCBtXXWV6jSwlMxZkt', created_at=1723408446, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-SQH2HT1IvRszon9pdYwV1yvQ', result_files=[], seed=335027432, status='validating_files', trained_tokens=None, training_file='file-4U0ALDbq0fatlKa349EeuETQ', validation_file='file-Zq9XglqitaAcXvvtT2Z109cW', estimated_finish=None, integrations=[], user_provided_suffix='sports_headlines')\n"
     ]
    }
   ],
   "source": [
    "# Create a fine-tuning job using the uploaded training data\n",
    "sports_headlines_ft_job = client.fine_tuning.jobs.create(\n",
    "    model=\"gpt-4o-mini-2024-07-18\",  # Base model to be fine-tuned\n",
    "    training_file=sports_headlines_train_file.id,  # ID of the uploaded training data file\n",
    "    validation_file=sports_headlines_test_file.id,  # ID of the uploaded validation (test) data file\n",
    "    hyperparameters={\n",
    "        \"batch_size\": \"auto\",  # Let API automatically determine batch size\n",
    "        \"learning_rate_multiplier\": \"auto\",  # Auto-set learning rate multiplier\n",
    "        \"n_epochs\": \"auto\",  # Automatically decide number of training epochs\n",
    "    },\n",
    "    suffix=\"sports_headlines\",  # Append this to the fine-tuned model's name\n",
    "    integrations=None,  # No specific integrations used\n",
    "    seed=None,  # No specific random seed set for reproducibility\n",
    ")\n",
    "print(\"Fine-tuning job created successfully!\")\n",
    "print(sports_headlines_ft_job)\n",
    "keep_running = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve and Print Validation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current status: validating_files\n",
      "Current status: running\n",
      "Current status: running\n",
      "Current status: running\n",
      "Current status: running\n",
      "Current status: running\n",
      "Current status: running\n",
      "Current status: running\n",
      "Current status: running\n",
      "Current status: running\n",
      "Current status: running\n",
      "Current status: succeeded\n",
      "Job succeeded. Final job details:\n",
      "FineTuningJob(id='ftjob-djbWbqzCBtXXWV6jSwlMxZkt', created_at=1723408446, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal:sports-headlines:9v9iuuIi', finished_at=1723409098, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-SQH2HT1IvRszon9pdYwV1yvQ', result_files=['file-bZZvotnmT3Kfcfp1yjP9pSPb'], seed=335027432, status='succeeded', trained_tokens=20244, training_file='file-4U0ALDbq0fatlKa349EeuETQ', validation_file='file-Zq9XglqitaAcXvvtT2Z109cW', estimated_finish=None, integrations=[], user_provided_suffix='sports_headlines')\n"
     ]
    }
   ],
   "source": [
    "# Check the status of the fine-tuning job\n",
    "# Continue checking until the job is complete or fails\n",
    "job_id = sports_headlines_ft_job.id  \n",
    "final_job = check_fine_tuning_status(client, job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File saved as step_metrics_ft_gpt-4o-mini-2024-07-18_personal_sports-headlines_9v9iuuIi.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_mean_token_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.49688</td>\n",
       "      <td>0.81818</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.20318</td>\n",
       "      <td>0.90000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.30965</td>\n",
       "      <td>0.89286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.99305</td>\n",
       "      <td>0.91429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.13596</td>\n",
       "      <td>0.90323</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>236</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>237</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>238</td>\n",
       "      <td>0.00025</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>239</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>240</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     step  train_loss  train_accuracy  valid_loss  valid_mean_token_accuracy\n",
       "0       1     1.49688         0.81818         NaN                        NaN\n",
       "1       2     1.20318         0.90000         NaN                        NaN\n",
       "2       3     1.30965         0.89286         NaN                        NaN\n",
       "3       4     0.99305         0.91429         NaN                        NaN\n",
       "4       5     1.13596         0.90323         NaN                        NaN\n",
       "..    ...         ...             ...         ...                        ...\n",
       "235   236     0.00009         1.00000         NaN                        NaN\n",
       "236   237     0.00007         1.00000         NaN                        NaN\n",
       "237   238     0.00025         1.00000         NaN                        NaN\n",
       "238   239     0.00003         1.00000         NaN                        NaN\n",
       "239   240     0.00004         1.00000     0.00006                        1.0\n",
       "\n",
       "[240 rows x 5 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch and process metrics for the sports headlines fine-tuning job\n",
    "fetch_and_process_fine_tuning_metrics(client, sports_headlines_ft_job.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the New Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieved Job Details:\n",
      "----------------------\n",
      "Job ID: ftjob-djbWbqzCBtXXWV6jSwlMxZkt\n",
      "Status: succeeded\n",
      "Model: gpt-4o-mini-2024-07-18\n",
      "Created At: 1723408446\n",
      "Finished At: 1723409098\n",
      "Fine-tuned Model: ft:gpt-4o-mini-2024-07-18:personal:sports-headlines:9v9iuuIi\n",
      "Organization ID: org-SQH2HT1IvRszon9pdYwV1yvQ\n",
      "Result Files: file-bZZvotnmT3Kfcfp1yjP9pSPb\n",
      "Trained Tokens: 20244\n",
      "Hyperparameters:\n",
      "    - Epochs: 3\n",
      "    - Batch Size: 1\n",
      "    - Learning Rate Multiplier: 1.8\n",
      "Training File: file-4U0ALDbq0fatlKa349EeuETQ\n",
      "Validation File: file-Zq9XglqitaAcXvvtT2Z109cW\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the fine-tuning job by ID\n",
    "retrieved_job = client.fine_tuning.jobs.retrieve(sports_headlines_ft_job.id)\n",
    "\n",
    "# Print detailed information about the retrieved job\n",
    "print(f\"\"\"\n",
    "Retrieved Job Details:\n",
    "----------------------\n",
    "Job ID: {retrieved_job.id}\n",
    "Status: {retrieved_job.status}\n",
    "Model: {retrieved_job.model}\n",
    "Created At: {retrieved_job.created_at}\n",
    "Finished At: {retrieved_job.finished_at or 'Not finished yet'}\n",
    "Fine-tuned Model: {retrieved_job.fine_tuned_model or 'Not available yet'}\n",
    "Organization ID: {retrieved_job.organization_id}\n",
    "Result Files: {', '.join(retrieved_job.result_files) if retrieved_job.result_files else 'None'}\n",
    "Trained Tokens: {retrieved_job.trained_tokens or 'Not available'}\n",
    "Hyperparameters:\n",
    "    - Epochs: {retrieved_job.hyperparameters.n_epochs}\n",
    "    - Batch Size: {retrieved_job.hyperparameters.batch_size}\n",
    "    - Learning Rate Multiplier: {retrieved_job.hyperparameters.learning_rate_multiplier}\n",
    "Training File: {retrieved_job.training_file}\n",
    "Validation File: {retrieved_job.validation_file}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Response:\n",
      "{\"player\": \"Simone Biles\", \"team\": null, \"sport\": \"gymnastics\", \"gender\": \"female\" }\n",
      "\n",
      "Formatted JSON Response:\n",
      "{\n",
      "  \"player\": \"Simone Biles\",\n",
      "  \"team\": null,\n",
      "  \"sport\": \"gymnastics\",\n",
      "  \"gender\": \"female\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Use the fine-tuned model to generate a completion\n",
    "try:\n",
    "    completion = client.chat.completions.create(\n",
    "        model=retrieved_job.fine_tuned_model,  # Use the fine-tuned model\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Given a sports headline, provide the following fields in a JSON dict, where applicable: \\\"player\\\" (full name), \\\"team\\\", \\\"sport\\\", and \\\"gender\\\".\"},\n",
    "            {\"role\": \"user\", \"content\": \"2024 Olympics: Biles earns 7th gold in dominant fashion\"},\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Print the generated response\n",
    "    print(\"Generated Response:\")\n",
    "    print(completion.choices[0].message.content)\n",
    "    \n",
    "    # Attempt to parse and pretty-print the JSON response\n",
    "    try:\n",
    "        json_response = json.loads(completion.choices[0].message.content)\n",
    "        print(\"\\nFormatted JSON Response:\")\n",
    "        print(json.dumps(json_response, indent=2))\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"\\nNote: The response is not in valid JSON format.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while generating the completion: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool Calling: Weather Example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validate the Data File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 100\n",
      "First example:\n",
      "{'role': 'system', 'content': 'You are a helpful assistant that can retrieve weather information.'}\n",
      "{'role': 'user', 'content': \"What's the weather like in Paris?\"}\n",
      "{'role': 'assistant', 'content': None, 'function_call': {'name': 'get_current_weather', 'arguments': '{\"location\": \"Paris, France\", \"format\": \"celsius\"}'}}\n",
      "{'role': 'function', 'name': 'get_current_weather', 'content': '{\"location\": \"Paris, France\", \"temperature\": 19.0, \"unit\": \"°C\", \"humidity\": 55, \"condition\": \"sunny\"}'}\n",
      "{'role': 'assistant', 'content': \"Currently in Paris, the weather is sunny with a temperature of 19.0°C and humidity at 55%. It's a pleasant day, perfect for a walk by the Seine or a visit to the Eiffel Tower.\"}\n",
      "\n",
      "\n",
      "Found possible issues:\n",
      "missing_content: 100\n",
      "\n",
      "\n",
      "Summary of dataset processing:\n",
      "Num examples missing system message: 0\n",
      "Num examples missing user message: 0\n",
      "Total number of examples: 100\n",
      "Average number of messages per example: 5.00\n",
      "Average number of total tokens per example: 147.59\n",
      "Average number of assistant tokens per example: 65.28\n",
      "0 examples may be over the 64000 token limit and will be truncated during fine-tuning\n",
      "\n",
      "\n",
      "Dataset Statistics:\n",
      "- Number of training examples: 100\n",
      "- Approximate billable tokens: 14759\n",
      "- Default number of epochs: 3\n",
      "- Estimated total billable tokens: 44277\n"
     ]
    }
   ],
   "source": [
    "# Path to the JSONL data file\n",
    "data_path = \"./artifacts/get_current_weather.jsonl\"\n",
    "\n",
    "try:\n",
    "    # Load and print the dataset\n",
    "    dataset = load_and_print_dataset(data_path)\n",
    "    print(\"\\n\")  # Add a blank line for better readability\n",
    "\n",
    "    # Check for format errors in the dataset\n",
    "    format_errors = check_format_errors(dataset)\n",
    "    print(\"\\n\")  # Add a blank line for better readability\n",
    "\n",
    "    # Process the dataset to extract message counts and token lengths\n",
    "    n_messages, convo_lens, assistant_message_lens = process_dataset(\n",
    "        dataset, \n",
    "        num_tokens_from_messages, \n",
    "        num_assistant_tokens_from_messages\n",
    "    )\n",
    "    print(\"\\n\")  # Add a blank line for better readability\n",
    "\n",
    "    # Get the total number of examples in the dataset\n",
    "    n_train_examples = len(dataset)\n",
    "\n",
    "    # Print statistics about the dataset\n",
    "    print_dataset_statistics(n_train_examples, convo_lens)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file {data_path} was not found.\")\n",
    "    sys.exit(1)\n",
    "except json.JSONDecodeError:\n",
    "    print(f\"Error: The file {data_path} is not a valid JSON Lines file.\")\n",
    "    sys.exit(1)\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {str(e)}\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data saved to: artifacts\\get_current_weather_train.jsonl\n",
      "Test data saved to: artifacts\\get_current_weather_test.jsonl\n",
      "Train set size: 80\n",
      "Test set size: 20\n",
      "\n",
      "\n",
      "Train file path: artifacts\\get_current_weather_train.jsonl\n",
      "Test file path: artifacts\\get_current_weather_test.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Path to the original JSONL data file\n",
    "data_path = \"./artifacts/get_current_weather.jsonl\"\n",
    "\n",
    "try:\n",
    "    # Split the JSONL file into training and testing sets\n",
    "    train_test_files = split_jsonl_file(data_path)\n",
    "    print(\"\\n\")  # Add a blank line for better readability\n",
    "\n",
    "    # Convert file paths to strings\n",
    "    train_path, test_path = [str(file) for file in train_test_files]\n",
    "\n",
    "    # Print the paths of the resulting train and test files\n",
    "    print(f\"Train file path: {train_path}\")\n",
    "    print(f\"Test file path: {test_path}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file {data_path} was not found.\")\n",
    "    sys.exit(1)\n",
    "except ValueError as e:\n",
    "    print(f\"Error in splitting the file: {str(e)}\")\n",
    "    sys.exit(1)\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {str(e)}\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Upload the Training File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the training data to the OpenAI API\n",
    "get_current_weather_train_file = client.files.create(\n",
    "            file=open(\"./artifacts/get_current_weather_train.jsonl\", \"rb\"),\n",
    "            purpose=\"fine-tune\"\n",
    "            ) \n",
    "\n",
    "# Upload the test data to the OpenAI API\n",
    "get_current_data_test_file = client.files.create(\n",
    "            file=open(\"./artifacts/get_current_weather_test.jsonl\", \"rb\"),\n",
    "            purpose=\"fine-tune\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking every two hours for the the job to be done\n",
    "retry_interval=7200 # every 2 hours\n",
    "attempt = 1\n",
    "while True:\n",
    "    try:\n",
    "        get_current_weather_ft_job = client.fine_tuning.jobs.create(\n",
    "            model=\"gpt-4o-mini-2024-07-18\",\n",
    "            training_file=get_current_weather_train_file.id, \n",
    "            validation_file=get_current_data_test_file.id,\n",
    "            hyperparameters={\n",
    "                \"batch_size\": \"auto\",\n",
    "                \"learning_rate_multiplier\": \"auto\",\n",
    "                \"n_epochs\": \"auto\",\n",
    "            },\n",
    "            suffix=\"get-weather\",\n",
    "            integrations=None,\n",
    "            seed=None,\n",
    "        )\n",
    "        print(\"Fine-tuning job created successfully!\")\n",
    "    except RateLimitError as e:\n",
    "        print(f\"Attempt {attempt}: Rate limit exceeded. Retrying in {retry_interval//3600} hours...\")\n",
    "        time.sleep(retry_interval)\n",
    "        attempt += 1\n",
    "    except Exception as e:\n",
    "        print(f\"Attempt {attempt}: An unexpected error occurred: {str(e)}\")\n",
    "        print(f\"Retrying in {retry_interval//3600} hours...\")\n",
    "        time.sleep(retry_interval)\n",
    "        attempt += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_current_weather_ft_job = client.fine_tuning.jobs.create(\n",
    "            model=\"gpt-4o-mini-2024-07-18\",\n",
    "            training_file=get_current_weather_train_file.id, \n",
    "            validation_file=get_current_data_test_file.id,\n",
    "            hyperparameters={\n",
    "                \"batch_size\": \"auto\",\n",
    "                \"learning_rate_multiplier\": \"auto\",\n",
    "                \"n_epochs\": \"auto\",\n",
    "            },\n",
    "            suffix=\"get-weather\",\n",
    "            integrations=None,\n",
    "            seed=None,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to monitor fine-tuning job with ID: ftjob-BZESclQIpEHu6u6omnK4bwok\n",
      "Current status: running\n",
      "Current status: running\n",
      "Current status: running\n",
      "Current status: running\n",
      "Current status: running\n",
      "Current status: running\n",
      "Current status: running\n",
      "Current status: running\n",
      "Current status: running\n",
      "Current status: succeeded\n",
      "Job succeeded. Final job details:\n",
      "FineTuningJob(id='ftjob-BZESclQIpEHu6u6omnK4bwok', created_at=1723451159, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal:get-weather:9vKolhs0', finished_at=1723451745, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-SQH2HT1IvRszon9pdYwV1yvQ', result_files=['file-bLCiuBkvrh4j0dKFyWkbPBLk'], seed=274768513, status='succeeded', trained_tokens=95295, training_file='file-nyk8noJx5fdab32xeqNkvbfg', validation_file='file-YQICDJhqVt8uqW9hp4a50n61', estimated_finish=None, integrations=[], user_provided_suffix='get-weather')\n",
      "\n",
      "Final job details:\n",
      "Status: succeeded\n",
      "Created at: 1723451159\n",
      "Finished at: 1723451745\n",
      "Fine-tuned model: ft:gpt-4o-mini-2024-07-18:personal:get-weather:9vKolhs0\n",
      "Fine-tuning status check process completed.\n"
     ]
    }
   ],
   "source": [
    "# Usage: Check the status of the fine-tuning job\n",
    "try:\n",
    "    # Extract the job ID from the previously created fine-tuning job\n",
    "    job_id = get_current_weather_ft_job.id\n",
    "    print(f\"Starting to monitor fine-tuning job with ID: {job_id}\")\n",
    "\n",
    "    # Check the fine-tuning status until completion or failure\n",
    "    final_job = check_fine_tuning_status(client, job_id)\n",
    "    \n",
    "    # Print the final job details\n",
    "    print(\"\\nFinal job details:\")\n",
    "    print(f\"Status: {final_job.status}\")\n",
    "    print(f\"Created at: {final_job.created_at}\")\n",
    "    print(f\"Finished at: {final_job.finished_at}\")\n",
    "    print(f\"Fine-tuned model: {final_job.fine_tuned_model}\")\n",
    "    # You can add more job details here if needed\n",
    "\n",
    "except AttributeError:\n",
    "    print(\"Error: 'job' object does not have 'id' attribute. \"\n",
    "        \"Make sure the job was created successfully.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {str(e)}\")\n",
    "\n",
    "finally:\n",
    "    print(\"Fine-tuning status check process completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the New Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to simulate getting the current weather for a location\n",
    "def get_current_weather(location: str, format: str = \"celsius\"):\n",
    "    \"\"\"\n",
    "    Get the current weather for a given location.\n",
    "\n",
    "    Args:\n",
    "    location (str): The location to get weather for.\n",
    "    format (str): The temperature format, either \"celsius\" or \"fahrenheit\". Defaults to \"celsius\".\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary containing weather information.\n",
    "    \"\"\"\n",
    "    # List of possible weather conditions\n",
    "    weather_conditions = [\"sunny\", \"partly cloudy\", \"cloudy\", \"rainy\", \"stormy\"]\n",
    "    \n",
    "    # Generate random temperature and humidity\n",
    "    temperature = random.uniform(-10, 35)\n",
    "    humidity = random.randint(30, 90)\n",
    "    \n",
    "    # Convert temperature to Fahrenheit if requested\n",
    "    if format.lower() == \"fahrenheit\":\n",
    "        temperature = (temperature * 9/5) + 32\n",
    "    \n",
    "    # Prepare and return the weather data\n",
    "    return {\n",
    "        \"location\": location,\n",
    "        \"temperature\": round(temperature, 1),\n",
    "        \"unit\": \"°F\" if format.lower() == \"fahrenheit\" else \"°C\",\n",
    "        \"humidity\": humidity,\n",
    "        \"condition\": random.choice(weather_conditions)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Job Details:\n",
      "Job ID: ftjob-BZESclQIpEHu6u6omnK4bwok\n",
      "Status: succeeded\n",
      "Model: gpt-4o-mini-2024-07-18\n",
      "Created At: 1723451159\n",
      "Finished At: 1723451745\n",
      "Fine-tuned Model: ft:gpt-4o-mini-2024-07-18:personal:get-weather:9vKolhs0\n",
      "Organization ID: org-SQH2HT1IvRszon9pdYwV1yvQ\n",
      "Result Files: file-bLCiuBkvrh4j0dKFyWkbPBLk\n",
      "Status: succeeded\n",
      "Trained Tokens: 95295\n",
      "Hyperparameters:\n",
      "  - Epochs: 3\n",
      "  - Batch Size: 1\n",
      "  - Learning Rate Multiplier: 1.8\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the details of a specific fine-tuning job\n",
    "\n",
    "try:\n",
    "    # Retrieve the fine-tuning job by its ID\n",
    "    retrieved_job = client.fine_tuning.jobs.retrieve(get_current_weather_ft_job.id)\n",
    "\n",
    "    # Print detailed information about the retrieved job\n",
    "    print(\"Retrieved Job Details:\")\n",
    "    print(f\"Job ID: {retrieved_job.id}\")\n",
    "    print(f\"Status: {retrieved_job.status}\")\n",
    "    print(f\"Model: {retrieved_job.model}\")\n",
    "    print(f\"Created At: {retrieved_job.created_at}\")\n",
    "    print(f\"Finished At: {retrieved_job.finished_at or 'Not finished yet'}\")\n",
    "    print(f\"Fine-tuned Model: {retrieved_job.fine_tuned_model or 'Not available yet'}\")\n",
    "    print(f\"Organization ID: {retrieved_job.organization_id}\")\n",
    "    print(f\"Result Files: {', '.join(retrieved_job.result_files) if retrieved_job.result_files else 'None'}\")\n",
    "    print(f\"Status: {retrieved_job.status}\")\n",
    "    print(f\"Trained Tokens: {retrieved_job.trained_tokens}\")\n",
    "    print(\"Hyperparameters:\")\n",
    "    print(f\"  - Epochs: {retrieved_job.hyperparameters.n_epochs}\")\n",
    "    print(f\"  - Batch Size: {retrieved_job.hyperparameters.batch_size}\")\n",
    "    print(f\"  - Learning Rate Multiplier: {retrieved_job.hyperparameters.learning_rate_multiplier}\")\n",
    "\n",
    "except AttributeError:\n",
    "    print(\"Error: 'job' object does not have 'id' attribute. Make sure the job was created successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while retrieving the job: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Query: What's the weather like in Tokyo?\n",
      "\n",
      "Step 1: Initial API call for function calling\n",
      "\n",
      "Function Call Details:\n",
      "Function Name: get_current_weather\n",
      "Arguments: {\"location\": \"Tokyo, Japan\", \"format\": \"celsius\"}\n",
      "\n",
      "Step 2: Simulating weather data retrieval\n",
      "Weather Data: {\n",
      "  \"location\": \"Tokyo, Japan\",\n",
      "  \"temperature\": 32.9,\n",
      "  \"unit\": \"\\u00b0C\",\n",
      "  \"humidity\": 68,\n",
      "  \"condition\": \"stormy\"\n",
      "}\n",
      "\n",
      "Step 3: Second API call for human-readable response\n",
      "\n",
      "Final Response:\n",
      "Currently in Tokyo, the weather is stormy with a temperature of 32.9°C and 68% humidity. Be cautious and stay indoors if possible.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_weather_response(user_input):\n",
    "    print(\"Step 1: Initial API call for function calling\")\n",
    "    # First API call to get the function call\n",
    "    response = client.chat.completions.create(\n",
    "        model=retrieved_job.fine_tuned_model,  \n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that can retrieve weather information.\"},\n",
    "            {\"role\": \"user\", \"content\": user_input}\n",
    "        ],\n",
    "        functions=[{\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather for a specific location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\"type\": \"string\", \"description\": \"The city and country, e.g., 'London, UK'\"},\n",
    "                    \"format\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"], \"description\": \"The temperature unit to use\"}\n",
    "                },\n",
    "                \"required\": [\"location\"]\n",
    "            }\n",
    "        }],\n",
    "        function_call=\"auto\"\n",
    "    )\n",
    "    \n",
    "    # Extract and print function call details\n",
    "    function_call = response.choices[0].message.function_call\n",
    "    print(\"\\nFunction Call Details:\")\n",
    "    print(f\"Function Name: {function_call.name}\")\n",
    "    print(f\"Arguments: {function_call.arguments}\")\n",
    "    \n",
    "    print(\"\\nStep 2: Simulating weather data retrieval\")\n",
    "    # Here you would actually call your weather API with these arguments\n",
    "    # For this example, let's simulate a weather response\n",
    "    function_args = json.loads(function_call.arguments)\n",
    "    weather_data = get_current_weather(\n",
    "        location=function_args['location'],\n",
    "        format=function_args.get('format', 'celsius')\n",
    "    )\n",
    "    print(f\"Weather Data: {json.dumps(weather_data, indent=2)}\")\n",
    "    \n",
    "    print(\"\\nStep 3: Second API call for human-readable response\")\n",
    "    # Second API call to get the final response\n",
    "    final_response = client.chat.completions.create(\n",
    "        model=retrieved_job.fine_tuned_model,  \n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that can retrieve weather information.\"},\n",
    "            {\"role\": \"user\", \"content\": user_input},\n",
    "            {\"role\": \"assistant\", \"content\": None, \"function_call\": function_call},\n",
    "            {\"role\": \"function\", \"name\": \"get_current_weather\", \"content\": json.dumps(weather_data)}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return final_response.choices[0].message.content\n",
    "\n",
    "# Example usage\n",
    "user_query = \"What's the weather like in Tokyo?\"\n",
    "print(f\"User Query: {user_query}\\n\")\n",
    "response = get_weather_response(user_query)\n",
    "print(\"\\nFinal Response:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Our Train/Test Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data saved to: artifacts\\marv_fine_tune_train.jsonl\n",
      "Test data saved to: artifacts\\marv_fine_tune_test.jsonl\n",
      "Train set size: 80\n",
      "Test set size: 20\n",
      "\n",
      "\n",
      "Train file path: artifacts\\marv_fine_tune_train.jsonl\n",
      "Test file path: artifacts\\marv_fine_tune_test.jsonl\n"
     ]
    }
   ],
   "source": [
    "# File paths and data processing\n",
    "file_path = \"./artifacts/marv_fine_tune.jsonl\"\n",
    "\n",
    "# Split the JSONL file into train and test sets\n",
    "wandb_train_test_files = split_jsonl_file(file_path)\n",
    "print(\"\\n\")  # Print a blank line for better output readability\n",
    "\n",
    "# Convert the returned file paths to strings\n",
    "wandb_train_path, wandb_test_path = [str(file) for file in train_test_files]\n",
    "\n",
    "# Print the paths of the resulting train and test files\n",
    "print(f\"Train file path: {wandb_train_path}\")\n",
    "print(f\"Test file path: {wandb_test_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the Train/Test Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the training data to the OpenAI API\n",
    "wandb_train__set_file = client.files.create(\n",
    "            file=open(wandb_train_path, \"rb\"),\n",
    "            purpose=\"fine-tune\"\n",
    "            )\n",
    "\n",
    "# Upload the test data to the OpenAI API\n",
    "wandb_test_set_file = client.files.create(\n",
    "            file=open(wandb_test_path, \"rb\"),\n",
    "            purpose=\"fine-tune\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Fine-Tuning Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a fine-tuning job using the uploaded training data\n",
    "wandb_params_ft_job = client.fine_tuning.jobs.create(\n",
    "    model=\"gpt-4o-mini-2024-07-18\",  # Base model to be fine-tuned\n",
    "    training_file=wandb_train__set_file.id,  # ID of the uploaded training data file\n",
    "    validation_file=wandb_test_set_file.id,  # ID of the uploaded validation (test) data file\n",
    "    hyperparameters={\n",
    "        \"batch_size\": \"auto\",  # Let API automatically determine batch size\n",
    "        \"learning_rate_multiplier\": \"auto\",  # Auto-set learning rate multiplier\n",
    "        \"n_epochs\": \"auto\",  # Automatically decide number of training epochs\n",
    "    },\n",
    "    suffix=\"marv_wandb_tune\",  # Append this to the fine-tuned model's name\n",
    "    integrations=[\n",
    "        {\n",
    "            \"type\": \"wandb\",\n",
    "            \"wandb\": {\n",
    "                \"project\": \"Marv_Fun_Tune_v2\",  # Replace with your actual project name\n",
    "                \"name\": \"Marv_run_001\",  # Optional: Replace with your desired run name or remove\n",
    "                \"entity\": \"suspicious-cow-self\",  # Optional: Replace with your entity or remove\n",
    "                \"tags\": [\"rando_tag1\", \"rando_tag2\"]  # Optional: Replace with your desired tags or remove\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    seed=None,  # Specific random seed set for reproducibility\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check to Make Sure the Job is Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to monitor fine-tuning job with ID: ftjob-WcdcO2exERwuEIK1fEcM2JBT\n",
      "Current status: validating_files\n",
      "Current status: running\n",
      "Current status: running\n",
      "Current status: running\n",
      "Current status: running\n",
      "Current status: running\n",
      "Current status: running\n",
      "Current status: running\n",
      "Current status: running\n",
      "Current status: running\n",
      "Current status: running\n",
      "Current status: succeeded\n",
      "Job succeeded. Final job details:\n",
      "FineTuningJob(id='ftjob-WcdcO2exERwuEIK1fEcM2JBT', created_at=1723400659, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal:marv-wandb-tune:9v7hfQoT', finished_at=1723401333, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-SQH2HT1IvRszon9pdYwV1yvQ', result_files=['file-9rvOEZkwsslSW94AI2J0GcBU'], seed=32159879, status='succeeded', trained_tokens=10542, training_file='file-oeSDEG9qQLA9aGSL3wN8yLsO', validation_file='file-4sbdIBCMl6yGsqIpVrjmuA0c', estimated_finish=None, integrations=[FineTuningJobWandbIntegrationObject(type='wandb', wandb=FineTuningJobWandbIntegration(project='Marv_Fun_Tune_v2', entity='suspicious-cow-self', name=None, tags=None, run_id='ftjob-WcdcO2exERwuEIK1fEcM2JBT'))], user_provided_suffix='marv_wandb_tune')\n",
      "\n",
      "Final job details:\n",
      "Status: succeeded\n",
      "Created at: 1723400659\n",
      "Finished at: 1723401333\n",
      "Fine-tuned model: ft:gpt-4o-mini-2024-07-18:personal:marv-wandb-tune:9v7hfQoT\n",
      "Fine-tuning status check process completed.\n"
     ]
    }
   ],
   "source": [
    "# Usage: Check the status of the fine-tuning job\n",
    "try:\n",
    "    # Extract the job ID from the previously created fine-tuning job\n",
    "    job_id = wandb_params_ft_job.id\n",
    "    print(f\"Starting to monitor fine-tuning job with ID: {job_id}\")\n",
    "\n",
    "    # Check the fine-tuning status until completion or failure\n",
    "    final_job = check_fine_tuning_status(client, job_id)\n",
    "    \n",
    "    # Print the final job details\n",
    "    print(\"\\nFinal job details:\")\n",
    "    print(f\"Status: {final_job.status}\")\n",
    "    print(f\"Created at: {final_job.created_at}\")\n",
    "    print(f\"Finished at: {final_job.finished_at}\")\n",
    "    print(f\"Fine-tuned model: {final_job.fine_tuned_model}\")\n",
    "    # You can add more job details here if needed\n",
    "\n",
    "except AttributeError:\n",
    "    print(\"Error: 'job' object does not have 'id' attribute. \"\n",
    "        \"Make sure the job was created successfully.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {str(e)}\")\n",
    "\n",
    "finally:\n",
    "    print(\"Fine-tuning status check process completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Head Over to Weights and Biases\n",
    "\n",
    "https://wandb.ai/home"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "### Delete All Fine-Tuning Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all our fine-tuning jobs\n",
    "ft_jobs_list = client.fine_tuning.jobs.list()\n",
    "\n",
    "# Filter the list to only include jobs with a status of \"succeeded\"\n",
    "succeeded_jobs_list = [job for job in ft_jobs_list.data if job.status == \"succeeded\"]\n",
    "\n",
    "print(\"There are a total of \" + str(len(succeeded_jobs_list)) + \" successful jobs\\n\")\n",
    "\n",
    "print(\"===== Successful Jobs =====\")\n",
    "for job in succeeded_jobs_list:\n",
    "    print(job.id)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Loop through all succeeded jobs and mark the models for deletion if they exist\n",
    "# If a model doesn't exist then log it and continue to the next job\n",
    "# Most errors will be to delete models that don't exist because they have already been marked for deletion\n",
    "# NOTE: It can take a very long time for a model to be deleted after it has been marked for deletion\n",
    "# for job in succeeded_jobs_list:\n",
    "#     try:\n",
    "#         response = client.models.delete(job.fine_tuned_model)\n",
    "#         print(f\"Deleted model: {job.fine_tuned_model}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Failed to delete model {job.fine_tuned_model}: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NormalProgramming",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
