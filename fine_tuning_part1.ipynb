{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Fine-Tuning\n",
    "\n",
    "# Part 1 - Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univeral Code Used for the Entire Notebook\n",
    "\n",
    "Let's set up our libraries and client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries and modules\n",
    "\n",
    "# OpenAI library for API interaction and event handling\n",
    "from openai import OpenAI  \n",
    "\n",
    "# JSON library for handling JSON data\n",
    "import json\n",
    "\n",
    "# TikToken library for token counting\n",
    "import tiktoken\n",
    "\n",
    "# NumPy library for numerical operations\n",
    "import numpy as np\n",
    "\n",
    "# defaultdict from the collections module for dictionary with default values\n",
    "from collections import defaultdict\n",
    "\n",
    "# Math library for mathematical operations\n",
    "import math\n",
    "\n",
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the OpenAI client\n",
    "client = OpenAI()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Files Validation & Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 100\n",
      "First example:\n",
      "{'role': 'system', 'content': 'Marv is a factual chatbot that is also sarcastic.'}\n",
      "{'role': 'user', 'content': \"What's the tallest mountain in the world?\"}\n",
      "{'role': 'assistant', 'content': \"Mount Everest. It's only the tallest thing on the planet.\"}\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the dataset file\n",
    "data_path = \"./artifacts/marv_fine_tune.jsonl\"\n",
    "\n",
    "# Load the dataset\n",
    "with open(data_path, 'r', encoding='utf-8') as file:\n",
    "    dataset = [json.loads(line) for line in file]\n",
    "\n",
    "# Print initial dataset statistics\n",
    "print(\"Number of examples:\", len(dataset))\n",
    "print(\"First example:\")\n",
    "\n",
    "# Print messages from the first example in the dataset\n",
    "for message in dataset[0][\"messages\"]:\n",
    "    print(message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format Validation\n",
    "\n",
    "We can perform a variety of error checks to validate that each conversation in the dataset adheres to the format expected by the fine-tuning API. Errors are categorized based on their nature for easier debugging.\n",
    "\n",
    "1. **Data Type Check**: Checks whether each entry in the dataset is a dictionary (dict). Error type: `data_type`.\n",
    "\n",
    "2. **Presence of Message List**: Checks if a `messages` list is present in each entry. Error type: `missing_messages_list`.\n",
    "\n",
    "3. **Message Keys Check**: Validates that each message in the `messages` list contains the keys `role` and `content`. Error type: `message_missing_key`.\n",
    "\n",
    "4. **Unrecognized Keys in Messages**: Logs if a message has keys other than `role`, `content`, `weight`, `function_call`, and `name`. Error type: `message_unrecognized_key`.\n",
    "\n",
    "5. **Role Validation**: Ensures the `role` is one of \"system\", \"user\", or \"assistant\". Error type: `unrecognized_role`.\n",
    "\n",
    "6. **Content Validation**: Verifies that `content` has textual data and is a string. Error type: `missing_content`.\n",
    "\n",
    "7. **Assistant Message Presence**: Checks that each conversation has at least one message from the assistant. Error type: `example_missing_assistant_message`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors found\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to track format errors\n",
    "format_errors = defaultdict(int)\n",
    "\n",
    "# Iterate through each example in the dataset\n",
    "for ex in dataset:\n",
    "    # Check if the example is a dictionary\n",
    "    if not isinstance(ex, dict):\n",
    "        format_errors[\"data_type\"] += 1\n",
    "        continue\n",
    "    \n",
    "    # Retrieve the messages list from the example\n",
    "    messages = ex.get(\"messages\", None)\n",
    "    if not messages:\n",
    "        format_errors[\"missing_messages_list\"] += 1\n",
    "        continue\n",
    "    \n",
    "    # Check each message in the messages list\n",
    "    for message in messages:\n",
    "        # Check if required keys are present in the message\n",
    "        if \"role\" not in message or \"content\" not in message:\n",
    "            format_errors[\"message_missing_key\"] += 1\n",
    "        \n",
    "        # Check for any unrecognized keys in the message\n",
    "        if any(k not in (\"role\", \"content\", \"name\", \"function_call\", \"weight\") for k in message):\n",
    "            format_errors[\"message_unrecognized_key\"] += 1\n",
    "        \n",
    "        # Validate the role value in the message\n",
    "        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\", \"function\"):\n",
    "            format_errors[\"unrecognized_role\"] += 1\n",
    "        \n",
    "        # Check content and function_call in the message\n",
    "        content = message.get(\"content\", None)\n",
    "        function_call = message.get(\"function_call\", None)\n",
    "        if (not content and not function_call) or not isinstance(content, str):\n",
    "            format_errors[\"missing_content\"] += 1\n",
    "    \n",
    "    # Ensure at least one message from the assistant is present\n",
    "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
    "        format_errors[\"example_missing_assistant_message\"] += 1\n",
    "\n",
    "# Print the results of the error checks\n",
    "if format_errors:\n",
    "    print(\"Found errors:\")\n",
    "    for key, value in format_errors.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "else:\n",
    "    print(\"No errors found\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token Counting Utilities\n",
    "\n",
    "A few helpful utilities to be used in the rest of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Automatically get the encoding for a specific model\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "\n",
    "\n",
    "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
    "    \"\"\"\n",
    "    Calculate the number of tokens in a list of messages.\n",
    "    \n",
    "    Args:\n",
    "        messages (list): List of message dictionaries.\n",
    "        tokens_per_message (int): Base tokens per message.\n",
    "        tokens_per_name (int): Additional tokens for the 'name' field.\n",
    "\n",
    "    Returns:\n",
    "        int: Total number of tokens.\n",
    "    \"\"\"\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            try:\n",
    "                num_tokens += len(encoding.encode(str(value)))\n",
    "            except Exception as e:\n",
    "                print(f\"Error encoding key: {key}, value: {value}, type: {type(value)}\")\n",
    "                print(f\"Error message: {str(e)}\")\n",
    "                raise\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3  # Adding 3 tokens for end of sequence\n",
    "    return num_tokens\n",
    "\n",
    "def num_assistant_tokens_from_messages(messages):\n",
    "    \"\"\"\n",
    "    Calculate the number of tokens in assistant messages.\n",
    "    \n",
    "    Args:\n",
    "        messages (list): List of message dictionaries.\n",
    "\n",
    "    Returns:\n",
    "        int: Total number of tokens in assistant messages.\n",
    "    \"\"\"\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"assistant\":\n",
    "            num_tokens += len(encoding.encode(str(message[\"content\"])))  # Convert content to string\n",
    "    return num_tokens\n",
    "\n",
    "# Function to print the distribution of values\n",
    "def print_distribution(values, name):\n",
    "    \"\"\"\n",
    "    Print the distribution statistics of a list of values.\n",
    "    \n",
    "    Args:\n",
    "        values (list): List of numerical values.\n",
    "        name (str): Description of the values.\n",
    "    \"\"\"\n",
    "    print(f\"\\n#### Distribution of {name}:\")\n",
    "    print(f\"min / max: {min(values)} / {max(values)}\")\n",
    "    print(f\"mean / median: {np.mean(values)} / {np.median(values)}\")\n",
    "    print(f\"p5 / p95: {np.quantile(values, 0.05)} / {np.quantile(values, 0.95)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Warnings and Token Counts\n",
    "\n",
    "With some lightweight analysis we can identify potential issues in the dataset, like missing messages, and provide statistical insights into message and token counts.\n",
    "\n",
    "1. **Missing System/User Messages**: Counts the number of conversations missing a \"system\" or \"user\" message. Such messages are critical for defining the assistant's behavior and initiating the conversation.\n",
    "\n",
    "2. **Number of Messages Per Example**: Summarizes the distribution of the number of messages in each conversation, providing insight into dialogue complexity.\n",
    "\n",
    "3. **Total Tokens Per Example**: Calculates and summarizes the distribution of the total number of tokens in each conversation. Important for understanding fine-tuning costs.\n",
    "\n",
    "4. **Tokens in Assistant's Messages**: Calculates the number of tokens in the assistant's messages per conversation and summarizes this distribution. Useful for understanding the assistant's verbosity.\n",
    "\n",
    "5. **Token Limit Warnings**: Checks if any examples exceed the maximum token limit (16,385 tokens), as such examples will be truncated during fine-tuning, potentially resulting in data loss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples missing system message: 0\n",
      "Num examples missing user message: 0\n",
      "\n",
      "#### Distribution of num_messages_per_example:\n",
      "min / max: 3 / 3\n",
      "mean / median: 3.0 / 3.0\n",
      "p5 / p95: 3.0 / 3.0\n",
      "\n",
      "#### Distribution of num_total_tokens_per_example:\n",
      "min / max: 40 / 53\n",
      "mean / median: 46.01 / 46.0\n",
      "p5 / p95: 41.0 / 50.05\n",
      "\n",
      "#### Distribution of num_assistant_tokens_per_example:\n",
      "min / max: 5 / 19\n",
      "mean / median: 10.54 / 11.0\n",
      "p5 / p95: 7.0 / 15.0\n",
      "\n",
      "0 examples may be over the 16,385 token limit, they will be truncated during fine-tuning\n"
     ]
    }
   ],
   "source": [
    "# Warnings and tokens counts\n",
    "n_missing_system = 0\n",
    "n_missing_user = 0\n",
    "n_messages = []\n",
    "convo_lens = []\n",
    "assistant_message_lens = []\n",
    "for i, ex in enumerate(dataset):\n",
    "    messages = ex[\"messages\"]\n",
    "    if not any(message[\"role\"] == \"system\" for message in messages):\n",
    "        n_missing_system += 1\n",
    "    if not any(message[\"role\"] == \"user\" for message in messages):\n",
    "        n_missing_user += 1\n",
    "    n_messages.append(len(messages))\n",
    "    try:\n",
    "        convo_lens.append(num_tokens_from_messages(messages))\n",
    "        assistant_message_lens.append(num_assistant_tokens_from_messages(messages))\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing example {i}:\")\n",
    "        print(f\"Messages: {messages}\")\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "print(\"Num examples missing system message:\", n_missing_system)\n",
    "print(\"Num examples missing user message:\", n_missing_user)\n",
    "print_distribution(n_messages, \"num_messages_per_example\")\n",
    "print_distribution(convo_lens, \"num_total_tokens_per_example\")\n",
    "print_distribution(assistant_message_lens, \"num_assistant_tokens_per_example\")\n",
    "n_too_long = sum(l > 16385 for l in convo_lens)\n",
    "print(f\"\\n{n_too_long} examples may be over the 16,385 token limit, they will be truncated during fine-tuning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Estimation\n",
    "\n",
    "Finally, we estimate the total number of tokens that will be used for fine-tuning, which allows us to approximate the cost. It is worth noting that the duration of the fine-tuning jobs will also increase with the token count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Statistics:\n",
      "- Number of training examples: 100\n",
      "- Approximate billable tokens: 4601\n",
      "- Default number of epochs: 3\n",
      "- Estimated total billable tokens: 13803\n"
     ]
    }
   ],
   "source": [
    "# Constants\n",
    "MAX_TOKENS_PER_EXAMPLE = 16385\n",
    "TARGET_EPOCHS = 3\n",
    "MIN_TARGET_EXAMPLES = 100\n",
    "MAX_TARGET_EXAMPLES = 25000\n",
    "MIN_DEFAULT_EPOCHS = 1\n",
    "MAX_DEFAULT_EPOCHS = 25\n",
    "\n",
    "def calculate_epochs(n_train_examples):\n",
    "    \"\"\"Calculate the number of epochs based on the number of training examples.\"\"\"\n",
    "    if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:\n",
    "        return min(MAX_DEFAULT_EPOCHS, math.ceil(MIN_TARGET_EXAMPLES / n_train_examples))\n",
    "    elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES:\n",
    "        return max(MIN_DEFAULT_EPOCHS, MAX_TARGET_EXAMPLES // n_train_examples)\n",
    "    return TARGET_EPOCHS\n",
    "\n",
    "def calculate_billing_tokens(convo_lens):\n",
    "    \"\"\"Calculate the number of billing tokens in the dataset.\"\"\"\n",
    "    return sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in convo_lens)\n",
    "\n",
    "def print_dataset_statistics(n_train_examples, convo_lens):\n",
    "    \"\"\"Print the dataset statistics and billing information.\"\"\"\n",
    "    n_epochs = calculate_epochs(n_train_examples)\n",
    "    n_billing_tokens = calculate_billing_tokens(convo_lens)\n",
    "    \n",
    "    print(f\"Dataset Statistics:\")\n",
    "    print(f\"- Number of training examples: {n_train_examples}\")\n",
    "    print(f\"- Approximate billable tokens: {n_billing_tokens}\")\n",
    "    print(f\"- Default number of epochs: {n_epochs}\")\n",
    "    print(f\"- Estimated total billable tokens: {n_epochs * n_billing_tokens}\")\n",
    "\n",
    "# Print the dataset statistics\n",
    "n_train_examples = len(dataset)\n",
    "print_dataset_statistics(n_train_examples, convo_lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train / Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data saved to: artifacts\\marv_fine_tune_train.jsonl\n",
      "Test data saved to: artifacts\\marv_fine_tune_test.jsonl\n",
      "Train set size: 80\n",
      "Test set size: 20\n"
     ]
    }
   ],
   "source": [
    "# Train / Test Split Functions for JSONL Files\n",
    "def split_jsonl_file(file_path, train_ratio=0.8):\n",
    "    # Read the input file\n",
    "    file_path = Path(file_path)\n",
    "    with file_path.open('r', encoding='utf-8') as f:\n",
    "        data = [json.loads(line) for line in f]\n",
    "    \n",
    "    # Shuffle the data\n",
    "    random.shuffle(data)\n",
    "    \n",
    "    # Calculate split index\n",
    "    split_index = int(len(data) * train_ratio)\n",
    "    \n",
    "    # Split the data\n",
    "    train_data = data[:split_index]\n",
    "    test_data = data[split_index:]\n",
    "    \n",
    "    # Prepare output file paths\n",
    "    train_file = file_path.with_name(f\"{file_path.stem}_train{file_path.suffix}\")\n",
    "    test_file = file_path.with_name(f\"{file_path.stem}_test{file_path.suffix}\")\n",
    "    \n",
    "    # Write train data\n",
    "    with train_file.open('w', encoding='utf-8') as f:\n",
    "        for item in train_data:\n",
    "            json.dump(item, f)\n",
    "            f.write('\\n')\n",
    "    \n",
    "    # Write test data\n",
    "    with test_file.open('w', encoding='utf-8') as f:\n",
    "        for item in test_data:\n",
    "            json.dump(item, f)\n",
    "            f.write('\\n')\n",
    "    \n",
    "    print(f\"Train data saved to: {train_file}\")\n",
    "    print(f\"Test data saved to: {test_file}\")\n",
    "    print(f\"Train set size: {len(train_data)}\")\n",
    "    print(f\"Test set size: {len(test_data)}\")\n",
    "\n",
    "# Usage\n",
    "file_path = \"./artifacts/marv_fine_tune.jsonl\"\n",
    "split_jsonl_file(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Fine-Tuning Job\n",
    "\n",
    "### Uploading a Training File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the training data to the OpenAI API\n",
    "fine_tune_file = client.files.create(\n",
    "            file=open(\"./artifacts/marv_fine_tune.jsonl\", \"rb\"),\n",
    "            purpose=\"fine-tune\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Simple Fine-Tuning Job (Code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a fine-tuning job using the uploaded training data\n",
    "simple_ft_job = client.fine_tuning.jobs.create(\n",
    "    training_file=fine_tune_file.id, \n",
    "    model=\"gpt-4o-mini-2024-07-18\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Fine-Tuning Job with All Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a fine-tuning job using the uploaded training data\n",
    "all_params_ft_job = client.fine_tuning.jobs.create(\n",
    "        model=\"gpt-4o-mini-2024-07-18\",\n",
    "        training_file=fine_tune_file.id, \n",
    "        validation_file=None,\n",
    "        hyperparameters={\n",
    "            \"batch_size\": \"auto\",\n",
    "            \"learning_rate_multiplier\": \"auto\",\n",
    "            \"n_epochs\": \"auto\",\n",
    "        },\n",
    "        suffix=\"marv_fine_tune\",\n",
    "        integrations=None,\n",
    "        seed=None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the Training Metrics\n",
    "\n",
    "### Pulling Training Metrics Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineTuningJob(id='ftjob-KXGcxmec50aWpHgW2inr46a0', created_at=1722617934, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal:marv-fine-tune:9rq4BA6s', finished_at=1722618553, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-SQH2HT1IvRszon9pdYwV1yvQ', result_files=['file-GWVJQ3TwQTbA8hxBwLY8uHQo'], seed=1416352456, status='succeeded', trained_tokens=13203, training_file='file-9IPLWzIs12fTVroGIYEpmJGf', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix='marv_fine_tune')\n",
      "\n",
      "\n",
      "   step  train_loss  train_accuracy  valid_loss  valid_mean_token_accuracy\n",
      "0     1     6.22392         0.25000         NaN                        NaN\n",
      "1     2     4.60720         0.50000         NaN                        NaN\n",
      "2     3     3.75919         0.45455         NaN                        NaN\n",
      "3     4     2.88643         0.63636         NaN                        NaN\n",
      "4     5     5.09498         0.57143         NaN                        NaN\n",
      "5     6     3.30050         0.60000         NaN                        NaN\n",
      "6     7     4.60727         0.40000         NaN                        NaN\n",
      "7     8     2.34463         0.66667         NaN                        NaN\n",
      "8     9     3.13136         0.60000         NaN                        NaN\n",
      "9    10     1.19587         0.69231         NaN                        NaN\n",
      "\n",
      "File saved as step_metrics_ft_gpt-4o-mini-2024-07-18_personal_marv-fine-tune_9rq4BA6s.csv\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "# Function to replace colons with underscores for file names\n",
    "def replace_colons_with_underscores(input_string):\n",
    "    return input_string.replace(':', '_')\n",
    "\n",
    "# Get the training metrics for the fine-tuning job\n",
    "all_params_ft_job = client.fine_tuning.jobs.retrieve(all_params_ft_job.id)\n",
    "\n",
    "print(all_params_ft_job)\n",
    "print(\"\\n\")\n",
    "\n",
    "# File ID of the file you want to download\n",
    "file_id = all_params_ft_job.result_files[0]\n",
    "\n",
    "# Retrieve the file content directly\n",
    "response = client.files.content(file_id)\n",
    "\n",
    "# Decode the Base64 content\n",
    "decoded_content = base64.b64decode(response.content).decode('utf-8')\n",
    "\n",
    "# Create a DataFrame from the decoded content\n",
    "df = pd.read_csv(io.StringIO(decoded_content))\n",
    "\n",
    "# Display the first 10 rows of the DataFrame\n",
    "print(df.head(10))\n",
    "\n",
    "# If you still want to save the CSV file locally:\n",
    "metrics_file_name = \"step_metrics_\" + replace_colons_with_underscores(all_params_ft_job.fine_tuned_model + \".csv\")\n",
    "df.to_csv(metrics_file_name, index=False)\n",
    "print(f\"\\nFile saved as {metrics_file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Fine-Tuning Jobs\n",
    "\n",
    "### List Fine-Tuning Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list our fine-tuning jobs\n",
    "ft_jobs_list = client.fine_tuning.jobs.list()\n",
    "\n",
    "print(ft_jobs_list)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Print job IDs, objects, and statuses\n",
    "for job in ft_jobs_list.data:\n",
    "    print(job.id, job.object, job.status)\n",
    "\n",
    "\n",
    "# Print detailed information for only the first job in the list\n",
    "job = ft_jobs_list.data[0]\n",
    "\n",
    "print(\"\\n\")\n",
    "print(f\"\"\"\n",
    "Job ID: {job.id}\n",
    "Created At: {job.created_at}\n",
    "Error: {job.error}\n",
    "Fine-tuned Model: {job.fine_tuned_model}\n",
    "Finished At: {job.finished_at}\n",
    "Hyperparameters:\n",
    "    - Epochs: {job.hyperparameters.n_epochs}\n",
    "    - Batch Size: {job.hyperparameters.batch_size}\n",
    "    - Learning Rate Multiplier: {job.hyperparameters.learning_rate_multiplier}\n",
    "Model: {job.model}\n",
    "Object: {job.object}\n",
    "Organization ID: {job.organization_id}\n",
    "Result Files: {', '.join(job.result_files)}\n",
    "Seed: {job.seed}\n",
    "Status: {job.status}\n",
    "Trained Tokens: {job.trained_tokens}\n",
    "Training File: {job.training_file}\n",
    "Validation File: {job.validation_file}\n",
    "Estimated Finish: {job.estimated_finish}\n",
    "Integrations: {', '.join(job.integrations) if job.integrations else 'None'}\n",
    "User Provided Suffix: {job.user_provided_suffix}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving Fine-Tuning Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the fine-tuning job by ID\n",
    "retrieved_job = client.fine_tuning.jobs.retrieve(job.id)\n",
    "\n",
    "print(f\"\"\"\n",
    "retrieved_job ID: {retrieved_job.id}\n",
    "Created At: {retrieved_job.created_at}\n",
    "Error: {retrieved_job.error}\n",
    "Fine-tuned Model: {retrieved_job.fine_tuned_model}\n",
    "Finished At: {retrieved_job.finished_at}\n",
    "Hyperparameters:\n",
    "    - Epochs: {retrieved_job.hyperparameters.n_epochs}\n",
    "    - Batch Size: {retrieved_job.hyperparameters.batch_size}\n",
    "    - Learning Rate Multiplier: {retrieved_job.hyperparameters.learning_rate_multiplier}\n",
    "Model: {retrieved_job.model}\n",
    "Object: {retrieved_job.object}\n",
    "Organization ID: {retrieved_job.organization_id}\n",
    "Result Files: {', '.join(retrieved_job.result_files)}\n",
    "Seed: {retrieved_job.seed}\n",
    "Status: {retrieved_job.status}\n",
    "Trained Tokens: {retrieved_job.trained_tokens}\n",
    "Training File: {retrieved_job.training_file}\n",
    "Validation File: {retrieved_job.validation_file}\n",
    "Estimated Finish: {retrieved_job.estimated_finish}\n",
    "Integrations: {', '.join(retrieved_job.integrations) if job.integrations else 'None'}\n",
    "User Provided Suffix: {retrieved_job.user_provided_suffix}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Checkpoints\n",
    "\n",
    "### Listing Job Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all fine-tuning job checkpoints\n",
    "ft_jobs_checkpoints_list = client.fine_tuning.jobs.checkpoints.list(my_ft_job.id)\n",
    "\n",
    "print(ft_jobs_checkpoints_list)\n",
    "print(\"\\n\\n\")\n",
    "for checkpoint in ft_jobs_checkpoints_list:\n",
    "    print(checkpoint.id, checkpoint.fine_tuned_model_checkpoint, checkpoint.step_number, checkpoint.created_at, checkpoint.metrics.train_loss, checkpoint.fine_tuning_job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Fine-tuning Events\n",
    "\n",
    "### List Fine-Tuning Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the events for the first fine-tuning job in our list\n",
    "ft_events_list = client.fine_tuning.jobs.list_events(\n",
    "            fine_tuning_job_id=job.id,\n",
    "            limit=10\n",
    "        )\n",
    "\n",
    "print(ft_events_list)\n",
    "print(\"\\n\\n\")\n",
    "for event in ft_events_list.data:\n",
    "    print(event.id, event.object, event.created_at, event.level, event.type, event.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cancelling Fine-Tuning Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a fine-tuning job using the uploaded training data\n",
    "dead_ft_job_walking = client.fine_tuning.jobs.create(\n",
    "        model=\"gpt-3.5-turbo-0125\",\n",
    "        training_file=fine_tune_file.id, \n",
    "        validation_file=None,\n",
    "        hyperparameters={\n",
    "            \"batch_size\": \"auto\",\n",
    "            \"learning_rate_multiplier\": \"auto\",\n",
    "            \"n_epochs\": \"auto\",\n",
    "        },\n",
    "        suffix=\"dead_walking\",\n",
    "        integrations=None,\n",
    "        seed=None,\n",
    "    )\n",
    "\n",
    "# Cancel the fine-tuning job\n",
    "client.fine_tuning.jobs.cancel(dead_ft_job_walking.id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the events for the cancelled job\n",
    "ft_events_list = client.fine_tuning.jobs.list_events(\n",
    "            fine_tuning_job_id=dead_ft_job_walking.id,\n",
    "        )\n",
    "\n",
    "print(ft_events_list)\n",
    "print(\"\\n\\n\")\n",
    "for event in ft_events_list.data:\n",
    "    print(event.id, event.object, event.created_at, event.level, event.type, event.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Fine-Tuned Models\n",
    "\n",
    "### Using Fine-Tuned Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all our fine-tuning jobs\n",
    "ft_jobs_list = client.fine_tuning.jobs.list()\n",
    "\n",
    "# Print job IDs, objects, and statuses for the filtered list\n",
    "print(\"===== All Jobs =====\")\n",
    "for job in ft_jobs_list:\n",
    "    print(job.id, job.object, job.status)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Filter the list to only include jobs with a status of \"succeeded\"\n",
    "succeeded_jobs_list = [job for job in ft_jobs_list.data if job.status == \"succeeded\"]\n",
    "\n",
    "print(\"===== Successful Jobs =====\")\n",
    "\n",
    "# Print job IDs, objects, and statuses for the filtered list\n",
    "for job in succeeded_jobs_list:\n",
    "    print(job.id, job.object, job.status)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the fine-tuned model to generate a completion\n",
    "completion = client.chat.completions.create(\n",
    "    model=succeeded_jobs_list[0].fine_tuned_model,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is limburger cheese?\"},\n",
    "    ]\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Checkpointed Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all fine-tuning job checkpoints\n",
    "ft_jobs_checkpoints_list = client.fine_tuning.jobs.checkpoints.list(succeeded_jobs_list[0].id)\n",
    "\n",
    "\n",
    "for checkpoint in ft_jobs_checkpoints_list:\n",
    "    print(checkpoint.id, checkpoint.fine_tuned_model_checkpoint, checkpoint.step_number, checkpoint.created_at, checkpoint.metrics.train_loss, checkpoint.fine_tuning_job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first checkpoint from the paginated results\n",
    "first_checkpoint = next(iter(ft_jobs_checkpoints_list), None)\n",
    "\n",
    "if first_checkpoint:\n",
    "    # Use the checkpointed model to generate a completion\n",
    "    completion = client.chat.completions.create(\n",
    "        model=first_checkpoint.fine_tuned_model_checkpoint,  # Note: changed from fine_tuned_model_checkpoint\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"},\n",
    "            {\"role\": \"user\", \"content\": \"What is limburger cheese?\"},\n",
    "        ]\n",
    "    )\n",
    "    print(completion.choices[0].message.content)\n",
    "else:\n",
    "    print(\"No checkpoints found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NormalProgramming",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
